package com.university.utils;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;

public class Data {
    
    public static final List<String> NAMES = new ArrayList<>(Arrays.asList(
            "Клара Викторовна Дейнина", "Георгий Юрьевич Жмалов", "Тамара Василевна Чайничкова", "Алена Викторовна Кантаева", "Клара Аркадьевна Фоминцова", "Артём Алексеевич Гамалеев", "Елизавета Аркадьевна Воргалова", "Борис Евгеньевич Струлев", "Алина Аркадьевна Шулутова", "Екатерина Алексеевна Киткова", "Иван Евгеньевич Буцыкин", "Руслан Борисович Типугин", "Катерина Леонидовна Ременькова", "Игорь Николаевич Коптелов", "Алла Романовна Жежурина", "Наталья Яковлевна Мезенцова", "Максим Валериевич Кисихин", "Эдуард Тимофеевич Стуцкий", "Ева Егоровна Радкеева", "Александра Никитична Юлаева", "Дмитрий Аркадиевич Путицкий", "Евгения Ивановна Ляпичева", "Роман Максимович Умаров", "Маргарита Валерьевна Иммореева", "Пётр Василиевич Шмитов", "Олег Фёдорович Кильдушкин", "Юрий Петрович Угольцов", "Михаил Юриевич Богдашин", "Ярослав Юрьевич Мелузов", "София Евгеньевна Заорская", "Артём Петрович Телентинов", "Павел Фёдорович Гаторинов", "Вероника Олеговна Саралаева", "Карина Николаевна Бронская", "Иван Леонидович Аранин", "Герасим Николаевич Бочакин", "Оксана Богдановна Петряшова", "Антон Павлович Аверичев", "Светлана Никитична Пентина", "Раиса Олеговна Гудайкина", "Евгения Федоровна Суходеева", "Алиса Яковлевна Правдюкова", "Георгий Антонович Столоногов", "Георгий Георгиевич Христнев", "Михаил Антонович Хаммов", "Марина Василевна Пчелина", "Семён Юрьевич Пыликов", "Алла Эдуардовна Брюнова", "Вероника Андреевна Шешелева", "Марина Романовна Лелекина", "Руслан Яковлевич Чиколин", "Виктор Кириллович Бродулев", "Инна Борисовна Посцелова", "Антон Валериевич Завельский", "Денис Кириллович Мазалецкий", "Кирилл Николаевич Дудовцев", "Антон Сергеевич Самохватов", "Оксана Викторовна Урбанская", "Любовь Алексеевна Мужицкая", "Алиса Петровна Вьюгова", "Виктория Андреевна Рахлеева", "Георгий Игоревич Скальский", "Светлана Аркадьевна Абалкина", "Зинаида Андреевна Жагурина", "Василий Олегович Дружбин", "Артур Кириллович Болтенков", "Аркадий Сергеевич Маканин", "Светлана Михайловна Борминская", "Валерия Валерьевна Скодтаева", "Григорий Сергеевич Тропанов", "Ольга Эдуардовна Габинова", "Максим Аркадиевич Патюков", "Вера Игоревна Кисурина", "Ирина Эдуардовна Любарская", "Семён Иванович Каноков", "Тарас Фёдорович Уварушкин", "Никита Максимович Головлин", "Оксана Егоровна Чепурнова", "Виктор Борисович Маначаров", "Илья Михаилович Юхнев", "Тамара Максимовна Димитрова", "Надежда Игоревна Куронова", "Инна Максимовна Суркина", "Елена Эдуардовна Широнова", "Федор Вадимович Гонзалев", "Павел Николаевич Леваев", "Лариса Василевна Таова", "Валентина Богдановна Бегенжова", "Владислав Романович Шандыков", "Станислав Романович Путилин", "Анастасия Богдановна Жибарова", "Михаил Максимович Тургамбаев", "Лариса Яковлевна Горисова", "Альберт Романович Зулкарниев", "Роман Василиевич Картушин", "Вероника Игоревна Плигунова", "Ольга Валерьевна Графуткина", "Яков Олегович Ловнев", "Кира Яковлевна Яфизова", "Михаил Алексиевич Чурков"
    ));


    public static final List<String> BUILD_PROECT_USE_INF_SYS_LECTURES = new ArrayList<>(Arrays.asList(
            "Принципы построения, проектирования и эксплуатации ИС. Лекция 1.\n" +
                    "Современное состояние Computer Science характеризуется тем, что, помимо естественных данных — результатов научных наблюдений, метеорологических данных, социологических и др., — появляется огромное количество данных, связанных\n" +
                    "сработой информационных систем. Эти новые данные существенно отличаются от тех, что анализировались на заре компьютерной эры. Те старые данные (их можно условно назвать естественнонаучными) в основном требовали математической обработки.\n" +
                    "В отличие от них данные современных информационных систем (большие данные) не могут быть представлены простыми математическими моделями, чьи параметры следует определить. Кроме того, эти данные отличаются существенной неоднородностью, разнообразной и непредсказуемой структурой, и зачастую непонятно, как их обрабатывать и нужно ли это вообще? Можно ли в них найти чтолибо полезное? Этих данных настолько много, что их анализ за разумное время требует вычислительных ресурсов, существенно превышающих вычислительныe ресурсы самой информационной системы. Это значит, что данные часто лежат мертвым грузом, несмотря на скрытые в них закономерности, составляющие полезную информацию, которую требуется найти. Поиск таких закономерностей называется Data Mining — добывание данных из груды пустых данных (по аналогии\n" +
                    "спустой породой). Что значит «обрабатывать» данные, и как их добывать? Для ответа на все приведенные вопросы необходимо сначала выяснить, откуда берутся эти большие данные. Их источниками могут быть:\n" +
                    "• социальные сети — посты, комментарии, сообщения между пользователями и пр.;\n" +
                    "• события, связанные с действиями пользователей в веб или мобильных приложениях;\n" +
                    "• логи приложений;\n" +
                    "• телеметрия сети устройств из мира «Интернета вещей» (Internet of Things, IoT); потоки событий крупных вебприложений;\n" +
                    "• потоки транзакций банковских платежей с метаданными (время, место платежа и т.д.).\n" +
                    "Все эти данные должны быть обработаны в режиме реального времени или же постфактум. В обоих случаях они могут размещаться в различных хранилищах (как общего назначения, так и специализированных) и в разных форматах: CVS, XML, JSON, таблицы в реляционных БД, базах данных NoSQL и пр.\n" +
                    "Для пакетной обработки исторических данных различных форматов, расположенных в разных хранилищах, необходим единый подход,\n" +
                    "\n" +
                    "обеспечивающий выполнение запросов к данным, хранящимся в указанных выше форматах. В настоящее время распространены следующие подходы.\n" +
                    "1.Преобразование данных из различных форматов в общий, допускающий выполнение запросов к единообразным данным. Это можно сделать с помощью облачных сервисов трансформации и копирования, таких как Azure Data Factory и AWS Glue, которые консолидируют данные из разных источников в один. Такое хранилище традиционно называется Data Warehouse (DWH, «склад данных»), а преобразование данных — ETL (Extract Transform Load — «извлечение, преобразование, загрузка»). Данный подход достаточно распространен в традиционных системах, в которых DWH строится на основе кластера SQLсерверов. Подход позволяет использовать все элементы синтаксиса SQL.\n" +
                    "2. Складирование данных в единое хранилище без изменения формата. При этом форматы данных остаются прежними (JSON, XML, CSV и т. д). Такое хранилище, в котором данные размещаются в виде несвязанного набора данных, называется Data Lake («озеро данных»). Файловая система, лежащая в основе подобных хранилищ, совместима с HDFS — распределенной файловой системой, которая, в свою очередь, совместима с Hadoop (Azure Data Lake, AWS EMRFS). Такое хранилище позволяет задействовать сервисы из экосистемы Hadoop (например, Hive, Apache Spark и др.) и применять иной подход к операциям\n" +
                    "с данными: ELT (Extract Load Transform — «извлечение, загрузка, преобразование»), когда данные можно трансформировать после загрузки. При этом используется сервер аналитики или кластер серверов, содержащий процессор специализированного языка запросов, в котором все разнородные источники данных представляются как внешние источники данных, к которым применим SQLподобный синтаксис. Для подобного хранилища также может использоваться подход MapReduce (будет более подробно описан далее) и обработка данных в оперативной памяти (in memory processing).\n" +
                    "3. Кроме того, для обработки потоковых данных существуют специализированные сервисы, допускающие обработку потока сообщений с помощью SQLподобного синтаксиса (например, сервисы Azure Stream Analytics, AWS Kinesis Analytics) или программных структур (Apache Spark Streaming), а также сервисы для приема и концентрации этих сообщений (например, Azure Event Hub, Kafka, Azure Spark и пр.).\n" +
                    "Прежде всего большие данные - это огромные массивы данных или потоки,\n" +
                    "которые содержат подлежащую извлечению информацию, или же умеренно большие объемы данных, требующие быстрой интерактивной обработки с целью исследования, проверки гипотез, тренировки алгоритмов машинного обучения. Для выполнения этой обработки необходим высокий уровень параллелизма,\n" +
                    "\n" +
                    "большой объем оперативной памяти (для in memory processing), что достигается применением кластеров виртуальных машин. Вот тутто и проявляются все преимущества облачных сред: модель IaaS позволяет создавать кластеры удалять их по требованию с минимальными затратами. Виртуальные серверы создаются и задействуются только в течение того промежутка времени, когда они нужны, и, соответственно, плата за них взимается только во время прямого использования. Но просто создание кластера для обработки больших данных с последующей установкой требуемых программ и их настройкой — весьма трудоемкое занятие. Кроме того, облачные провайдеры предоставляют отдельные сервисы PaaS больших данных.\n" +
                    "Обработка больших данных\n" +
                    "Большие данные могут быть обработаны в пакетном режиме, когда они уже присутствуют в хранилище. Чаще всего это необходимо для агрегирования данных и построения аналитических отчетов на их основе. Рассмотрим в качестве примера систему мониторинга электроэнергии сети зданий. В этой системе замеры потребляемой мощности передаются с малой периодичностью как сообщения от каждого измерительного модуля. Чтобы получить величину дневного потребления электроэнергии, необходимо сложить все замеры сизмерительного модуля каждого пользователя в отдельности. Если итоговый результат нужно, к примеру, формировать в виде ежедневного (еженедельного, ежемесячного и пр.) отчета, то наиболее просто реализовать такую систему следующим образом.\n" +
                    "Архитектура системы учета электроэнергии, построенная на основе разделения хранилищ сырых и агрегированных данных — так называемая лямбдаархитектура\n" +
                    "Все сообщения от измерительных устройств можно хранить в нереляционном хранилище табличного типа (этот вопрос подробнее рассматривается в части II), например HBase или Cassandra. Каждая строка таблицы будет содержать\n" +
                    " \n" +
                    "временну'ю метку (то есть время поступления или отправления сообщения), идентификатор устройства, его отправившего, и собственно величину замера.\n" +
                    "Для построения периодического отчета с помощью системы бизнесаналитики (business intelligence, BI) (например, PowerBI или Microsoft SSRS) или отображения этой величины в браузере необходимо, чтобы данные в агрегированном виде были размещены в БД SQL. А почему нельзя сразу размещать их непосредственно\n" +
                    "вэтой базе? Посчитаем. Предположим, что измерительное устройство отсылает сообщения каждые пять минут. Это значит — 12 отсчетов в час, или около 105 тыс.\n" +
                    "вгод. Теперь предположим, что система мониторинга собирает данные энергопотребления с каждого устройства заказчика, которых могут быть десятки, а самих заказчиков — тысячи. В итоге таблица, хранящая события в реляционной БД, будет содержать многие миллионы строк: допустим, при наличии 100 заказчиков со средним числом подключенных приборов 20 за год такая таблица пополнится 200 миллионами строк. Вот они, большие данные!\n" +
                    "Простое применение запроса на выборку данных к подобной таблице может занять очень много время. А если добавить еще необходимость постоянных запросов на обновление таблицы поступающими от устройств сообщениями, а также постоянные запросы от вебпортала или от пользователей на получение отчетов, то станут очевидны будущие проблемы такой архитектуры с одной базой данных. Пакетная же обработка с группировкой и суммированием результатов может быть выполнена, например, с использованием Hadoop MapReduce или Apache Spark. Сами алгоритмы группировки в данном случае можно реализовать с помощью программ на Java (для MapReduce, Spark) или Python (Spark) и запустить в кластере.\n" +
                    "Витоге размеры таблицы с агрегированными данными в базе данных SQL будут существенно меньше, чем в таблице с сырыми данными. Так, если хранится часовое агрегирование, то в SQLтаблице в 12 раз меньше строк, чем в NoSQL, а если суточное — то в 288 раз. При этом для клиентов запрос на получение данных будет очень простой и высокопроизводительный: выбрать из таблицы агрегатов строки, отфильтрованные по идентификатору заказчика и по требуемому временно'му интервалу без каких бы то ни было группировок в самом запросе.\n" +
                    "По поводу подобной архитектуры следует сделать целый ряд замечаний.\n" +
                    "1.Обеспечить высокую точность позволяет большое количество замеров, следующих с малым временны'м интервалом. Если интервал постоянный, то можно упустить включение/выключение прибора, произошедшее между замерами. Эта проблема решается путем передачи не периодических замеров, а замеров, приуроченных к событию: включению или изменению величины проходящей мощности более чем на заданную величину. Такое решение, вопервых, разгрузит сеть от слишком частых передач отсчетов (но не\n" +
                    "\n" +
                    "полностью — необходимо оставить периодические сообщения от измерителя о его работоспособности), и вовторых, существенно уменьшит объем сырой таблицы.\n" +
                    "2. В случае проблем с сетью и для обеспечения высокой точности вместе с требованием разгрузки сети необходимо физическое разделение отсчетов замера мощности на уровне АЦП измерительного прибора (они могут быть выполнены с высокой частотой дискретизации) и отсылка результатов суммирования измерений в виде сообщения в систему. Чтобы обеспечить это разделение, измерительное устройство должно быть достаточно «интеллектуальным»: обладать памятью и иметь возможность синхронизировать часы, чтобы установить временну'ю метку. Может показаться, что достаточно иметь момент времени приема сообщения, но это неверно. Для получения высокой точности и обеспечения надежности важно каждое сообщение. Они могут быть потеряны как изза отказа измерительного устройства, так и изза проблем с телекоммуникационной сетью. Чтобы устранить проблемы с сетью, устройство может запоминать сообщения и пересылать их, когда сеть восстановит работоспособность. И вот тутто очень важно, чтобы каждому сообщению была присвоена метка времени: когда оно сгенерировано. Это позволит в итоге правильно подсчитать суммарное энергопотребление в заданный временной интервал.\n" +
                    "Теперь рассмотрим еще один вопрос: а зачем вообще нужно промежуточное хранилище такого большого объема?\n" +
                    "Архитектура системы учета электроэнергии, построенная на основе единого реляционного хранилища данных\n" +
                    "Ведь можно периодически очищать сырую таблицу в SQLхранилище после заполнения данными агрегированной таблицы и хранить только результаты агрегирования. Действительно, при наличии данных энергопотребления в\n" +
                    " \n" +
                    "течение каждого дня недели/месяца/года можно легко подсчитать суммарное энергопотребление за бо'льшие периоды времени. Против такого подхода есть ряд возражений. Например, возможна ситуация, когда изза проблем с сетью не все устройства отослали свои данные вовремя. И если сырая таблица очистится перед тем, как восстановится работоспособность сети и устройства сбросят свои данные, то последние останутся неучтенными и не будет никакого смысла дополнительно усложнять измерители в виде внутреннего буфера сообщений и синхронизиру емых часов. В то же время реализация дополнительной логики, обеспечивающей пересчет агрегированных данных в пакетном режиме при приеме недостающих сообщений, позволит произвести правильный и надежный подсчет потребления даже при ненадежной сети передачи данных.\n" +
                    "Тут мы сталкиваемся еще с одним аспектом анализа больших данных: потоковой обработкой. В данном случае необходимо из всего потока сообщений обнаруживать те, чья временна'я метка меньше, чем текущее время минус самая большая временная задержка, и при их обнаружении запускать внепланово или планировать дополнительно запустить в определенное время (если построение агрегированных таблиц происходит в конкретное время, скажем по ночам) задачу по повторному пересчету. Для этой цели может служить, например, Apache Storm, Apache Spark Streaming или же Apache Pig.\n" +
                    "Следующая причина, побуждающая оставитьтаки сырую таблицу без удаления данных, — возможность провести интерактивный анализ хранящихся в ней данных. То есть применить к ним запросы на специальном языке, позволяющем комбинировать, фильтровать, группировать, проводить арифметические операции в режиме реального времени. Это позволяет находить скрытые закономерности в данных, например определять пики энергопотребления, устанавливать корреляцию их с внешними событиями (скажем, с погодой), определять профили пользователей, характеризующиеся оптимальным энергопотреблением. Или для одного пользователя строить типовой профиль применения энергоресурсов и обнаруживать отклонения от него (допустим, утечку электроэнергии, несвоевременное выключение освещения и пр.). Подобные задачи могут решаться с помощью системы интерактивного анализа данных, таких как Spark SQL или Apache Hive, арасширенный интеллектуальный анализ — благодаря применению библиотеки машинного обучения Spark MLib.\n" +
                    "Архитектура, содержащая в своем составе хранилища как сырых данных, так и агрегированных, является очень гибкой и позволит создать не просто очередную систему учета электроэнергии, но и интеллектуальную, которая может «подсказать», как уменьшить потребление энергии, где есть узкие места, а это уже принципиально новый уровень по сравнению с простой телеметрией. Такое развитие возможно благодаря тому, что данные в ней хранятся в том виде, в котором они наиболее удобны для выполнения анализа различными сервисами:\n" +
                    "\n" +
                    "для обычного сервиса построения отчетов об энергопотреблении — в агрегированном виде, а для целей Data Mining — в сыром.\n" +
                    "Ключевой момент всех технологий, работающих с большими данными, — возможность распараллеливания выполняемых задач, областей хранения, памяти и т. д. между группой компьютеров (кластер). Кроме того, эти технологии должны:\n" +
                    "• обладать возможностью линейного масштабирования и наращивания производительности путем добавления новых серверов в кластер. Линейность масштабирования означает пропорциональность производительности/объема хранения количеству компьютеров в кластере;\n" +
                    "• иметь специальную файловую систему для надежного хранения и доступа\n" +
                    "• данным, позволяющую оперировать очень большими объемами данных и допускать их репликацию в целях повышения надежности и производительности;\n" +
                    "• позволять выполнять запросы к файлам с помощью специального языка запросов или программного интерфейса;\n" +
                    "• иметь планировщик, позволяющий распределять эти запросы среди узлов кластера для обеспечения их параллельной работы.\n"
    ));
}
