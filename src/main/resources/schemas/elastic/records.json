{
  "took" : 22,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 22,
      "relation" : "eq"
    },
    "max_score" : 1.0,
    "hits" : [
      {
        "_index" : "lectureindex",
        "_type" : "_doc",
        "_id" : "82486845-3190-4d62-bd1c-6eed4016378f",
        "_score" : 1.0,
        "_source" : {
          "_class" : "com.university.entity.elastic.LectureElastic",
          "id" : "82486845-3190-4d62-bd1c-6eed4016378f",
          "text" : "Принципы построения, проектирования и эксплуатации ИС. Лекция 2.\nОблачные провайдеры позволяют подключать различные устройства, программные продукты, сервисы (игровые устройства, стационарные устройства IoT, подключенные автомобили, мобильные приложения, вебсерверы и серверы приложений, медиасервисы и пр.) через специальные сервисы концентраторов сообщений и шлюзы устройств «Интернета вещей» (IoT Gateway). Концентраторы (AWS Kinesis Stream, Azure Event Hub) обеспечивают однонаправленный прием сообщений извне в облако, а IoTшлюз (Azure IoT Hub) — двунаправленную коммуникацию с устройствами, то есть возможность обратной отсылки команд устройствам из облака. Этот поток может быть обработан сервисами потоковой обработки и анализа.\nК сервисам потокового анализа относятся сервисы, которые допускают интерактивный анализ потока данных и позволяют создавать аналитические запросы на специальном языке (чаще всего с SQLподобным синтаксисом), интерактивно их применять и отображать результаты (например, Azure Stream Analytics). К сервисам потоковой обработки относятся те, которые задействуют модули, написанные на компилируемых языках для построения потоковых задач анализа (таких как Apache Storm в HDInsight или AWS EMR) и не допускающие интерактивного использования.\nОблачные сервисы, относящиеся к большим данным\n \nСообщения, полученные от концентраторов или IoTшлюзов, могут быть направлены по своим назначениям, в зависимости от внутренних признаков (такая возможность обеспечивается системой маршрутизации сообщений: Azure Event Grid или аналогичной системой в IoTшлюзе), или целиком направлены в облачное хранилище. Это может быть либо хранилище общего назначения (типа Azure BLOB Storage или AWS S3), либо HDFSсовместимое (Azure Data Lake). Кроме того, данные в такое хранилище могут доставляться сервисами копирования и трансформации данных (AWS Glue или Azure DataFactoy) или специа лизированными сторонними программами через предоставляемые этими сервисами API. Источниками данных могут быть внешние реляционные и нереляционные базы данных и файлы. После размещения в облачном хранилище информацию можно обработать в пакетном режиме (например, с помощью Hadoop MapRerduce в Azure HDInsight или AWS EMR), интерактивном режиме (Azure Data Lake Analytics, AWS Athena) или с применением машинного обучения. Результаты обработки могут быть размещены в реляционном хранилище данных и доступны для средств BI (Microsoft PowerBI или AWS QuickSight).\nЛюбой облачный провайдер предоставляет сервисы IaaS, позволяющие создать ряд виртуальных машин, которые можно объединить в кластер. В этом случае пользователю придется самому создавать и конфигурировать нужный BigDataфреймворк. Ситуация в какойто мере облегчается тем, что имеются готовые образы виртуальных машин с предустановленными утилитами и компонентами. Но реализация IaaSрешения требует достаточно высокой квалификации у пользователей облачных сред. Ведь, помимо навыков инсталляции и конфигурирования образцов виртуальных машин, необходимо оперировать сервисами IaaS, чтобы построить нужную инфраструктуру, что требует больших затрат времени и обширных знаний, не относящихся к области BigData. Частично задачу упрощает тот факт, что облачные сервисы можно создавать с помощью шаблонов: AWS CloudFormation или Azure ARM Template. Но остаются сложности интеграции IaaSрешения с другими сервисами, сервисами логирования и мониторинга.\nВ то же время для каждого описанного компонента общей архитектуры, у облачных провайдеров Microsoft Azure и AWS существует свой PaaSсервис. Но у обоих провайдеров для ряда компонентов имеются два вида сервисов.\nК первому виду относятся сервисы, которые целиком применяют существующие фреймворки больших данных из экосистемы Hadoop. Задействуются стандартные средства взаимодействия с пользователем (например, Jupiter Notebook для написания запросов и отображения результатов). При этом создание, конфигурирование и масштабирование кластера полностью автоматизировано. К таким сервисам относятся Azure\n\n HDInsight и AWS EMR. Они позволяют разворачивать кластеры Hadoop, Spark, Storm, HBase, Kafka и RServer (только Azure). Кроме того, компоненты облачных сервисов могут быть размещены на кластерах AWS ECS / EKS или Azure Kontainer Services в Docker контейнерах. Ко второму виду относятся облачные сервисы, целиком и полностью (нативно) предоставляемые облачными провайдерами. Такие сервисы конфигурируются и управляются только из облачного портала или через его REST API и не используют сторонние средства и сервисы.\nАрхитектуры традиционных информационных систем\nДля получения представления о том, что такое большие данные, как они возникают и обрабатываются, следует подробнее разобраться с тем, что собой представляют современные информационные системы. Системы обработки больших данных подразумевают возможность, позволяющую реализовать не только систему обработки данных, но и приложение, которое решает конкретную бизнес-задачу. Эта идея — асинхронная передача сообщений (событий) между компонентами системы и применение отдельных сервисов, обеспечивающих надежную передачу сообщений. Казалось бы, практически любая информационная система имеет дело с обменом сообщений, представленном в том или ином виде, так что тут нового? Разберемся по порядку.\nМногие годы информационные системы строились в виде одного крупного монолита с единообразной кодовой базой, которая разворачивается на сервере как единое целое: вместе со всеми подключаемыми модулями, библиотеками и т. д. Такой монолит (рис. 3.2) отвечал за все (или почти): за взаимодействие с базами данных, обеспечение системы контроля учетных данных, работу периодических сервисов синхронизации, логирования и пр.\nНиже представлены проблемы, свойственные такой архитектуре.\n• Любое изменение в любом компоненте монолита, даже самое незначительное, требует компилирования и разворачивания всей системы, что при большом размере монолита задача весьма небыстрая.\n• Монолит очень плохо масштабируется и подвержен существенным проблемам использованием ресурсов. Действительно, как правило, подобные архитектуры разворачиваются на одном сервере или в виде полных копий на группе серверов. Поэтому любой компонент (или компоненты), который задействует ресурсы сервера (скажем, оперативную память, процессор и т. д.), в значительной степени может затруднить работу всего монолита и потребует увеличения производительности всего сервера, на котором расположена данная\n\nархитектура. Компоненты монолита невозможно масштабировать\nнезависимо.\n• Монолит жестко диктует стек технологий программирования, и\nобновить его, также обновить саму архитектуру — значит, по сути, переписать весь код заново. Сюда же можно отнести проблемы с быстрым «старением» монолита, склонностью к обрастанию спагеттикодом, а также «тупиковой внутренней архитектурой» — это когда невозможно исправить баг или улучшить чтолибо, не вызвав появления нового бага или ухудшения системы.\n• Сопровождение монолита может причинить множество неудобств программистам, системным администраторам, тестировщикам...\nМонолитная архитектура\nРешить указанные проблемы была призвана многослойная архитектура\n  \nМногослойная архитектура\nВ ней за специфическую задачу отвечает отдельный слой: пользовательского интерфейса (user interface layer, UI layer), бизнеслогики (business logic layer, BL layer) и доступа к данным (data access layer, DAL).\nРассмотрим эту архитектуру подробнее. Каждый слой отвечает только за определенную группу задач. UIслой содержит только вебсерверы, являющиеся источником вебстраниц, или размещает сервисы (REST, SOAP или др.) для взаимодействия с клиентскими приложениями. Кроме того, данный слой принимает запросы от клиентов и транслирует их слою бизнеслогики. Поскольку с клиентом напрямую взаимодействует только UIслой, то на одном уровне с ним в тесной интеграции находится сервис аутентификации клиентов. Слой BL содержит серверы приложений и отвечает, собственно, за бизнеслогику и интеграцию со сторонними сервисами. Слой DAL обеспечивает программный доступ слоя BL к базе данных и файловому хранилищу.\nПодобная архитектура по сравнению с монолитной имеет следующие преимущества.\n• Разделение на слои позволяет реализовать в каждом слое наиболее подходящий для него стек технологий. Можно независимо обновлять фреймворки на каждом слое.\n• Логическое разделение на слои существенно упрощает процесс разработки и сопровождение всей системы. Распределение команд программистов по слоям и специализация разработчиков (фронтенд, бэкенд), уменьшение объема кода на каждом слое, а также независимый деплой (развертывание) значительно улучшают качество всей системы, делая ее более гибкой и пригодной для сопровождения.\n• Возможно независимое масштабирование каждого слоя.\nНаиболее часто подобная архитектура реализуется в виде серверов, расположенных в локальной сети, разбитой на подсети с настроенными фаерволами. Адреса серверов (IP или URL) разных слоев и учетные данные для доступа к ним прописаны в конфигурационных файлах других серверов. В этой архитектуре уже необходимо централизованно хранить учетные данные, иметь серверы DNS, сервис хранения логов и мониторинга, а также сервер для администрирования.\nВмонолитной архитектуре все это могло быть расположено на одном большом общем сервере. Логирование также было весьма простым, поскольку вся система строилась в рамках одного стека технологий. В многослойной архитектуре каждый слой может генерировать логи,\n\nсущественно отличающиеся от логов другого слоя. Кроме того, увеличение количества серверов тоже ведет к увеличению количества и видов логов.\nМногослойная архитектура информационных систем в настоящее время чрезвычайно распространена, она более гибкая и удобная по сравнению с монолитной, однако не может решить ряд проблем. В частности, при разрастании проекта до такого масштаба, что слой BL становится сопоставимым с монолитом, появляются аналогичные проблемы с масштабированием, производительностью, сопровождением и т. д.\nСледующая разновидность многослойной архитектуры — SOA: сервис- ориентированная архитектура. Ее квинтэссенцией является архитектура микросервисов, суть которой заключается в том, что каждое приложение разбивается на наименьшие самостоятельные модули, и каждый из них отвечает только за один аспект: отсылку писем, загрузку и выгрузку файлов и пр. Каждый такой сервис можно совершенно независимо развернуть и обновить в любой момент, не затрагивая остальные сервисы. Код подобного сервиса может быть совсем небольшим, и для его сопровождения нужна маленькая команда. Более того, все микросервисы можно писать на разных языках, лучше всего подходящих для решения текущей задачи. И наконец, каждый микросервис может быть развернут на своем сервере или в кластере серверов, которые могут быть совершенно независимо масштабируемы. Каждый сервис доступен по URL конечной точки и из них, как из элементов конструктора, можно собрать новые системы, а каждый сервис использовать в различных системах.\nАрхитектура микросервисов\n \nОднако работа с микросервисной архитектурой предполагает ряд трудностей.\n• Большое количество сервисов, размещенных на многих серверах, означает большое количество разнообразных логов. По сути, вот они, большие данные! Анализ этих данных, определение метрик производительности, узких мест, поиск логов и отображение результатов в виде графиков в режиме, близкому режиму реального времени, требует не просто сервиса, но целой подсистемы, сопоставимой с основной системой. В качестве примера такой подсистемы можно привести ELK стек — Elasticsearch (хранение логов и поиск), Logstash (агенты, обеспечивающие доставку логов с серверов в кластер Elasticsearch) и Kibana (интерактивные диаграммы, графики и др.), Splunk.\n• Взаимодействие между сервисами происходит преимущественно с помощью REST. А потому каждый сервис должен знать URL всех сервисов, с которыми он может потенциально взаимодействовать.\n• Если по какойто причине запрос не был обработан (например, сервис был недоступен), то для его повторения необходимо организовать логику повтора в рамках самого кода.\nСинхронизировать работу микросервисов позволит отдельный сервис, обеспечивающий надежную доставку сообщений, а также предоставляющий малое количество конечных точек. И вот тут мы постепенно подходим к Event Driven Design — архитектуре, основанной на обмене сообщениями.\nАрхитектуры, построенные на базе микросервисов, каждый из которых можно разместить в кластере серверов, дополненные сервисами обмена сообщениями (брокерами сообщений — message brokers), могут быть чрезвычайно масштабируемыми. Для этого нужно, чтобы сами сервисы обмена сообщениями были масштабируемыми. Брокеры, как правило, имеют архитектуру с одним или несколькими головными узлами, отвечающими за управление кластером, и исполнительными узлами, на которых выполняются необходимые вычисления и хранятся данные (сообщения). Чтобы обеспечить надежность кластера, данные могут быть реплицированы между исполнительными узлами.\n \nОбщая структура масштабируемой системы, построенной на основе кластера\nПодобные структуры весьма сложны: кластеры серверов, балансировщики нагрузки, системы управления конфигурацией, логирования и пр.\nИсейчас самое время напомнить преимущества облачных платформ: все подобные системы представляются как сервисы — AWS ECS и Azure Service Fabric. Данные сервисы отвечают за масштабирование, мониторинг, развертывание приложений или контейнеров на них.\nВ облачных средах, наряду с сервисами PaaS, отвечающими за обработку больших данных, Azure и AWS предоставляют сервисы, занимающие промежуточное положение между IaaS и PaaS. Эти сервисы позволяют применять наиболее популярные фреймворки, работающие с большими данными, — Apache Spark, Storm, Kafka, HBase, Storm и ряд других. К таким сервисам относятся AWS EMR и Azure HDInsight. Они берут на себя все трудности, связанные с настройкой и конфигурированием сервисов в кластерах, а конечному пользователю предоставляют готовый и настроенный сервис. Это очень большое преимущество подобных сервисов по сравнению с ручным конфигурированием кластера из виртуальных машин. Практически все сервисы Apache Hadoop являются продуктами с открытым исходным кодом, имеют подробную документацию и поддержку обширного сообщества, однако их установка, настройка и конфигурирование на практике очень трудны.\nСервисы AWS EMR и Azure HDInsight занимают промежуточное положение между IaaS и PaaS, сочетая все возможности сервисов Apache с простотой PaaS. Эти сервисы представляют собой надстройки над набором виртуальных машин. Последние создаются, запускаются, останавливаются и удаляются только на время выполнения задания в сервисе или по мере надобности (как в случае Apache Kafka, например). Сервисы AWS EMR и Azure HDInsight очень хорошо интегрируются сервисами копирования и трансформации данных (Azure Data Factory), составляя, по сути, вычислительные ресурсы для заданий ETL. При создании кластеров с портала для HDInsight и AWS EMR указываются размеры виртуальных машин и сценарий, который должен выполняться при запуске сервиса. Создание и удаление управляемых кластеров полностью автоматизируемо, что и обусловливает удобство их использования в случае построения систем пакетного анализа, копирования и трансформации данных.\nБессерверные архитектуры\nАрхитектура, основанная на обмене сообщениями, характеризуется тем, что все компоненты системы взаимодействуют через малые порции сообщений, требующие вычислительных ресурсов только непосредственно в момент обработки сообщений. Все остальное время сервисы заняты только\n\nтем, что прослушивают конечные точки сервисов обмена сообщениями. Во время прослушивания серверы или виртуальные машины не загружены. Но в облачных средах принимается плата за включенную виртуальную машину вне зависимости от того, насколько интенсивно она используется. Таким образом, если поток сообщений не слишком сильный, то сервисы работают вхолостую. Но зачастую необходимо выполнить программу однократно или в непредсказуемые моменты времени в ответ на поступившее сообщение, для чего использовать виртуальную машину нецелесообразно. Для такого случая облачные провайдеры обеспечивают возможность выполнения кода по требованию без предоставления серверов — бессерверные сервисы (serverless). Подобный сервис от Microsoft называется Microsoft Azure Function, а от AWS — AWS Lambda. Последний является классическим вариантом. Этот сервис позволяет размещать исполняемый код и запускать его внешним событием, которое может прийти от сервисов SNS, SQS, Kinesis Stream, S3, API Gateway и др. Сам сервис имеет различные уровни производительности процессора и памяти, которые используются лишь при исполнении кода, и плата начисляется только этот момент.\nКонцепция serverless очень удобна для построения приложений с малым, средним и умеренно большим потоком сообщений.\nГлавные преимущества serverless таковы:\n• более дешевая среда исполнения кода, чем виртуальные машины, при небольших, средних и умеренно больших потоках;\n• более высокая надежность сервиса, чем в случае одиночной виртуальной машины, — SLA на уровне 99,9 %;\n• простота интеграции с другими облачными сервисами, не требующая внесения изменения в код;\n• простота развертывания кода и конфигурирования — необходимо только добавить код напрямую или через ZIP файл и выбрать уровень производительности.\nОднако подобным сервисам присущи и недостатки:\n• ограниченная масштабируемость;\n• ограниченное время выполнения кода;\nНо вместе с тем serverless сервисы крайне удобны для построения архитектур, основанных на событиях (event driven design).\n"
        }
      },
      {
        "_index" : "lectureindex",
        "_type" : "_doc",
        "_id" : "6df7a303-9ac0-4c97-9d0d-3c727ff4e0db",
        "_score" : 1.0,
        "_source" : {
          "_class" : "com.university.entity.elastic.LectureElastic",
          "id" : "6df7a303-9ac0-4c97-9d0d-3c727ff4e0db",
          "text" : "    Основы администрирования программно-аппаратных комплексов под управлением ОС Linux\n  Уровень\n(наименование дисциплины (модуля) в соответствии с учебным планом)\nспециалитет\n  Форма обучения\nНаправление(-я) подготовки\nИнститут Кафедра Лектор\nРТУ МИРЭА ЛЕКЦИОННЫЕ МАТЕРИАЛЫ\nочная\nкомплексной безопасности и приборостроения (КБСП)\nк.т.н., Потерпеев Герман Юрьевич\nМИНОБРНАУКИ РОССИИ\nФедеральное государственное бюджетное образовательное учреждение высшего образования\n«МИРЭА – Российский технологический университет»\n (бакалавриат, магистратура, специалитет)\n   (очная, очно-заочная, заочная)\n  10.05.04 «Информационно-аналитические системы безопасности»\n  (код(-ы) и наименование(-я))\n        (полное и краткое наименование)\n КБ-2 (Прикладные информационные технологии)\n  (полное и краткое наименование кафедры, реализующей дисциплину (модуль))\n           (сокращенно – ученая степень, ученое звание; полностью – ФИО)\n Используются в данной редакции с учебного года\n 2018/19\n     (учебный год цифрами)\n  Проверено и согласовано «____» ________20___г. Москва 20__ г.\n       (подпись директора Института/Филиала\n  с расшифровкой)\n     \nЛЕКЦИЯ No1\n«Современные ОС семейства Linux» по дисциплине\n«Основы администрирования программно-аппаратных комплексов под управлением ОС Linux»\n1)Современные ОС семейства Linux 2)Классификация современных ОС семейства Linux\n1)Современные ОС семейства Linux. История развития Linux.\nLinux — общее название UNIX-подобных операционных систем на основе одноимѐнного ядра и собранных для него библиотек и системных программ, разработанных в рамках проекта GNU. GNU/Linux работает на PC-совместимых системах семейства Intel x86, а также на IA-64, AMD64, PowerPC, ARM и многих других.\nК операционной системе GNU/Linux также часто относят программы, дополняющие эту операционную систему, и прикладные программы, делающие еѐ полноценной многофункциональной операционной средой. В отличие от большинства других операционных систем, GNU/Linux не имеет единой «официальной» комплектации. Вместо этого GNU/Linux поставляется в большом количестве так называемых дистрибутивов, в которых программы GNU соединяются с ядром Linux и другими программами.\nКорни Linux уходят в два других проекта: Unix и Multics, которые ставили своей целью разработать многопользовательскую операционную систему.\nЧто такое Unix?\nUnix – это собрание кроссплатформенных многопользовательских и многозадачных операционных систем.\nМожно сразу сказать, что в данный момент Unix-системы являются одними из самых исторических важных операционных систем. Влияние Unix распространилось и на языки программирования: язык C был разработан во время разработки Unix-систем.\nРазработкой Unix занималась корпорация Bell Laboratories – в 1969 году они показали первую систему Unix. Чем дальше, тем большую популярность обретали системы Unix - в 70-х их начали устанавливать на компьютеры в учебных заведениях.\nПри создании Unix разработчики поставили перед собой три основные задачи:\nИспользование минимального количества функций, сохранение простоты.\n\nОбщность: одинаковые методы и механизмы используются в разных случаях.\nКомбинирование программ для решения задач, а не разработка новых программ с нуля.\nЧто касается отличительных особенностей Unix, то это:\nПрактически постоянное использование командной строки.\nИспользование конвейнеров.\nНастройка системы через использование простых (зачастую текстовых) файлов.\nUnix имеет свою собственную философию. Программист Дуглас Макилрой, который разработал конвейнер в Linux, определил следующие правила:\nПишите программы, которые делают что-то одно и делают это хорошо. Пишите программы, которые бы работали вместе.\nПишите программы, которые бы поддерживали текстовые потоки, поскольку это универсальный интерфейс.\nОдна из проблем, коснувшаяся Unix, - наличие разных версий и множества программ, которые писали разработчики под свои нужды; из-за низкой совместимости программы, работающие с одной версией Unix, могли не работать на машинах с другими версиями. В итоге было решено создать общий документ, в котором будут указаны стандарты, которым должны следовать разработчики.\nВ 1983 году было объявлено о создании GNU (GNU’s Not UNIX), Unix-подобной операционной системы. Произошло это под влиянием идеи основателя проекта Ричарда Столманна о необходимости создания свободно распространяемой операционной системы и вообще программного обеспечения с открытым исходным кодом.\nРичард Столманн также основан движение свободного программного обеспечения и сформулирован четыре права, которыми должен обладать пользователь: он может запускать программу для любых целей, он может изучать программы и изменять их согласно своим потребностям, он может распространять программу, чтобы помочь другим, и он может публиковать улучшения программы, чтобы помочь сообществу в целом. Все это в первую очередь говорило о том, что исходный код программы должен быть доступен всем.\nИменно эта мысль вдохновила Линуса Торвальдса, создателя Linux, начать в 1991 году работу над своей операционной системой. Linux, как и GNU, это Unix-подобная система, то есть система, появившаяся под влиянием Unix.\n\nВ дальнейшем именно система GNU/Linux станет той системой, которую сейчас называют просто Linux.\nЧто такое Multics?\nMultics — или Multiplexed Information and Computing Service («Мультиплексная информационная и вычислительная служба») — это одна из самых первых операционных систем, в которой была реализована плоская модель хранения данных и четко разделена концепция файлов (сегментов). Создание Multics началось в 1964 году. Над системой работали разработчики компании Bell Laboratories — через несколько лет часть разработчиков начнет работу над созданием Unix.\nMultics разрабатывали для того, чтобы, во-первых, дать возможность использовать ресурсы ЭВМ большому количеству пользователей одновременно; во-вторых, дать пользователям возможность совместно использовать данные; в-третьих, обеспечить хорошую скорость работы с данными.\nОднако главные вычислительные задачи не были достигнуты при выпуске первой версии системы, и компания Bell Laboratories перевела свой интерес на другой проект, в результате которого на свет появился Unix.\nИстория Linux\nИстория Linux начинается в 1991 году, когда финский программист Линус Торвальдс стал разрабатывать ядро операционной системы для своего компьютера. Свои наработки он выложил на сервере, и это стало ключевым событием в истории Linux. Сначала десятки, потом сотни и тысячи разработчиков поддержали его проект - общими усилиями на свет появилась полноценная операционная система.\nКак уже было сказано, на Linux значительно повлияла система Unix, это заметно даже по названию. Впрочем, изначально проект назывался Freax - от слов ―free‖ (бесплатный) и ―freak‖ (странный), но в дальнейшем название было изменено на гибрид имени создателя (Линус) и Unix.\nЭмблемой Linux стал Такс (Tux) - пингвин, нарисованный в 1996 году программистом и дизайнером Ларри Юингом. Впрочем, идею использовать именно пингвина придумал сам Линус Торвальдс. Теперь Такс является символом не только Linux, но и свободного программного обеспечения в целом.\nПервая официальная версия Linux 1.0 вышла в 1994 году; вторая версия пошла в 1996 году. Товарный знак Linux был зарегистрирован на год раньше, в 1995.\nС самого начала и по сей день Linux распространяется как свободное программное обеспечение с лицензией GPL. Это значит, что исходный код операционной системы может увидеть любой пользователь - и не только увидеть, но и доработать его. Единственное условие - измененный, модифицированный код должен быть так же доступен всем и распространяться по лицензии GPL. Это важно, так как дает возможность разработчикам использовать код и в то же время не бояться проблем из-за авторских прав.\n\nСвоему успеху Linux во многом обязан GNU: на момент выхода Linux существовало уже много свободного распространяемых утилит этого проекта, которые можно было использовать с разработанным ядром.\nПо факту Linux до сих представляет собой ядро Unix-подобной операционной системы, которое выполняет различные низкоуровневые задачи. В то же время проект GNU нуждался в ядре - разработка Линуса Торвальдса была очень своевременной.\nСейчас благодаря своей гибкости Linux используется на множестве разных устройств, начиная от компьютеров и заканчивая серверами и мобильными устройствами.\nДистрибутив Linux – это определение операционной системы, которая использует ядро Linux, и которую можно установить на машину пользователя. В дистрибутивах обычно содержатся не только ядро и сама операционная система, но и полезные приложения: редакторы, проигрыватели, инструменты для работы с базами данных и другое программное обеспечение.\nТо есть, как уже было сказано в начале статьи, дистрибутив Linux – это операционная система, которая состоит из ядра Linux и утилит, которые разрабатываются в рамках GNU. Количество существующих дистрибутивов Linux превышает 600 разновидностей, более 300 из которых постоянно дорабатываются и обновляются.\n2)Классификация современных ОС семейства Linux\nБольшинство пользователей для установки GNU/Linux используют дистрибутивы. Дистрибутив — это не просто набор программ, а ряд решений для разных задач пользователей, объединѐнных едиными системами установки, управления и обновления пакетов, настройки и поддержки.\nСамые распространѐнные в мире дистрибутивы:\nUbuntu\nБыстро завоевавший популярность дистрибутив, ориентированный на лѐгкость в освоении и использовании.\nLinux Mint\nLinux Mint - дистрибутив, основанный на Ubuntu и Debian. Linux Mint обладает красивым и удобным дизайном и подойдет даже начинающим пользователям. Поэтому его часто устанавливают на домашние компьютеры для того, чтобы иметь простую и удобную систему. Дистрибутив имеет поддержку различных мультимедийных форматов, в том числе включает проприетарные программы (Adobe Flash), поэтому хорошо подходит для работы с мультимедиа.\n  \nopenSUSE\nБесплатно распространяемая версия дистрибутива SuSE, принадлежащая компании Novell. Отличается удобством в настройке и обслуживании благодаря использованию утилиты YaST.\nFedora\nПоддерживается сообществом и корпорацией RedHat, предшествует выпускам коммерческой версии RHEL.\nDebian\nМеждународный дистрибутив, разрабатываемый обширным сообществом разработчиков в некоммерческих целях. Послужил основой для создания множества других дистрибутивов. Отличается строгим подходом к включению несвободного ПО.\nMandriva\nФранцузско-бразильский дистрибутив, объединение бывших Mandrake и Conectiva.\nSlackware\nОдин из старейших дистрибутивов, отличается консервативным подходом в разработке и использовании.\nGentoo\nДистрибутив, собираемый из исходных кодов. Позволяет очень гибко настраивать конечную систему и оптимизировать производительность, поэтому часто называет себя мета-дистрибутивом. Ориентирован на экспертов и опытных пользователей.\nArchlinux\nОриентированный на применение самых последних версий программ и постоянно обновляемый, поддерживающий одинаково как бинарную, так и установку из исходных кодов и построенный на философии простоты «KISS» («Keep it simple, stupid» / «Не усложняй»), этот дистрибутив ориентирован на компетентных пользователей, которые хотят иметь всю силу и модифицируемость Linux, но не в жертву времени обслуживания.\nПомимо перечисленных, существует множество других дистрибутивов, как базирующихся на перечисленных, так и созданных с нуля и зачастую предназначенных для выполнения ограниченного количества задач.\nКаждый из них имеет свою концепцию, свой набор пакетов, свои достоинства и недостатки. Ни один не может удовлетворить всех пользователей, а потому рядом с\n       \nлидерами благополучно существуют другие фирмы и объединения программистов, предлагающие свои решения, свои дистрибутивы, свои услуги. Существует множество LiveCD, построенных на основе GNU/Linux, например, Knoppix. LiveCD позволяет запускать GNU/Linux непосредственно с компакт-диска, без установки на жѐсткий диск. Большинство крупных дистрибутивов, включая Ubuntu, могут быть использованы как LiveCD.\nДля желающих досконально разобраться с GNU/Linux подойдѐт любой из дистрибутивов, однако довольно часто для этой цели используются так называемые «source-based» дистрибутивы, то есть предполагающие самостоятельную сборку всех компонентов из исходных кодов, такие как LFS, Gentoo или CRUX.\nПрименение\nОбласть распространения Linux огромна, гораздо больше чем у вcех других операционных систем. Кроме того, что Linux прекрасно работает на обычных домашних и рабочих компьютерах и серверах, существуют адаптации Linux к большинству современных процессоров, что позволяет использовать системы с ядром Linux в сетевом оборудовании, домашней «умной» технике, роботах, мобильных телефонах, различных портативных устройствах и другом оборудовании, поддерживающем программируемые операции.\nВ конечном счѐте столь широкий круг поддерживаемых устройств означает превосходную переносимость программ. Например, одно и то же приложение зачастую можно запустить с минимальными усилиями и на обычном компьютере, и на мобильном телефоне на базе Linux. Для примера: Windows и еѐ младший брат Windows Mobile являются полностью несовместимыми платформами.\nОтдельно хотелось бы отметить одну особенную группу дистрибутивов – Puppy Linux. Puppy тоже можно назвать родительским, так как в его основе лежит не один из вышеперечисленных долгожителей, а достаточно интересные идеи. На базе Puppy создано немало мини-дистрибутивов, есть и локализованная отечественная версия – PuppyRus Linux. Это отдельная ветка Linux, стоящая особняком. Дистрибутивы достаточно молоды, а сообщество малочисленно (по сравнению с остальными дистрибутивами), но я считаю, что у этой вариации есть большие преимущества перед прочими дистрибутивами, если вам хочется лѐгкости, простоты и мобильности.\nНе секрет, что Linux – это своего рода конструктор. Много чего может не работать из коробки, а привыкшим к Windows пользователям при любых системных ошибках станет очень некомфортно. Поэтому данные мобильные мини-дистрибутивы очень хорошо подходят для первого знакомства. Они нетребовательны к железу, работают со сменных носителей, а переустановка системы займѐт 5 минут и по сути является просто копированием файла + перезагрузка ПК.\n "
        }
      },
      {
        "_index" : "lectureindex",
        "_type" : "_doc",
        "_id" : "2ec135d7-262d-4316-8aca-50870468e6b4",
        "_score" : 1.0,
        "_source" : {
          "_class" : "com.university.entity.elastic.LectureElastic",
          "id" : "2ec135d7-262d-4316-8aca-50870468e6b4",
          "text" : "Принципы построения, проектирования и эксплуатации ИС. Лекция 3.\nОблачные хранилища файлов — это сервисы, которые обеспечивают хранение файлов, предоставляют доступ к ним с помощью REST API, позволяют скачивание по прямой ссылке (постоянной или с конечным сроком действия) и в некоторых случаях предоставляют доступ к файловой системе по протоколу SMB.\nХранить файлы, содержащие большие данные, в облачном хранилище очень дешево и в ряде случаев удобнее, чем в других хранилищах. Наиболее типовой пример размещения данных — это хранение файлов логов приложения, которые копируются туда периодически из сервера источника или создаются и заполняются специальной программой клиентом, размещенной на сервере источнике логов.\nКроме того, в облачных файловых хранилищах могут размещаться виртуальные жесткие диски (virtual hard drive, VHD) облачных виртуальных машин, на которых,\nвсвою очередь, тоже можно размещать файлы. Но в этом случае ответственность за доступность информации ложится на владельца виртуальных машин. Рассмотрим подробнее различные форматы хранения больших данных.\n Структура потока логов серверов в облачное хранилище\n\nФорматы хранения данных\nКак уже отмечалось, наиболее типовой случай использования текстовых файлов для хранения больших данных — хранение логов приложений в том или ином текстовом формате. Такие файлы могут иметь расширения .log, .txt, .csv и др. Общее у этих форматов то, что логи в них, по сути, хранятся в виде таблицы (отсюда и название — табличный формат), каждая строка которой — запись конкретного события. Строка состоит из набора столбцов, разделенных некими символами. Это могут быть пробелы, символы табуляции, двоеточие, точка с запятой и т. д. Подобные файлы можно открыть с помощью любого текстового редактора (если они не очень велики), и для их анализа (например, поиска запросов с 500 ошибками) подойдут стандартные утилиты командной оболочки (grep, awk и пр.) или же специализированные сервисы аналитики (к этому вопросу мы еще вернемся). Кроме того, табличная структура подобного файла очень удобна для импорта в реляционную или нереляционную СУБД табличного типа. Особенность таких файлов — линейная структура со строго одинаковым количеством столбцов в каждой записи и в общем случае линейное время доступа к записям. Строго говоря, возможны ситуации, когда разные строки могут содержать различное количество столбцов. Например, запись в лог-файле, отражающая ошибку приложения и трассировку стека, может включать гораздо меньше строк, чем запись, отражающая какое-либо событие, характеризующее нормальную работу приложения. В общем же случае записи логов содержат как минимум временную метку. Остальные поля (уникальный идентификатор, URL, сообщение ошибки и пр.) могут и отсутствовать. Возникает вопрос: полезна ли запись с одним полем (временной меткой)? Да. Скажем, необходимо проанализировать посещаемость сайта во времени. Просуммировать запросы для заданного временного интервала (например, 15 минут) поможет именно временная метка.\nТабличные файлы имеют и ряд неудобств в использовании. Во-первых, для доступа к элементу информации необходимо знать номер строки и номер столбца. Нет универсального стандарта или языка запросов (за исключением SQL-подобного языка специализированных сервисов аналитики, но об этом позже), что весьма затрудняет анализ логов. Во-вторых, в таких форматах очень просто добавить новую запись в конец файла, но крайне трудно и затратно вставить, удалить или изменить произвольную строку. Как правило, все программные библиотеки вводавывода позволяют добавлять строку в конец файла с помощью стандартных средств, но для произвольной манипуляции данными программисту нужно будет создать отдельную логику в коде, и эта логика весьма непроста.\n\nПомимо текстового файла с табличной структурой, широко распространено хранение информации в более структурированных форматах JSON, XML. Их преимущества в том, что они очень удобны для сериализации/десериализации информации в объектноориентированном виде в коде программы. Кроме того, для обоих форматов существуют стандарты выполнения запросов на выборку данных (для XML — XPath, XQuery, для JSON — JSONPath, JSONQuery). Кратко рассмотрим эти форматы.\nJSON представляет собой формат, при котором данные хранятся в текстовом виде как объект JavaScript (аббревиатура образована от JavaScript Object Notation). В основе любого документа JSON лежит объект, который состоит из набора «ключ — значение». В качестве ключа выступают текстовые величины. В качестве значений допускаются следующие типы.\n• Атомарный тип (для ключей PlayerId, StepId) — величина, состоящая из одного конкретного значения: строки, числа, временно'й метки.\n• Массив (например Players) — группы величин одного типа. (Это не совсем точное определение, в общем случае все элементы массива могут быть совершенно разного типа, но, как правило, коллекции объектов, сериализуемые в JSON в реальных программах, будут иметь одинаковый тип.) В качестве типов элементов массива могут выступать атомарные типы, другие массивы или другие объекты. Массивы обозначаются прямоугольными скобками — [ ], а элементы в массиве разделяются запятыми, допустим: [ \"a\", \"c\", \"d\" ]. Доступ к элементу происходит по числовому индексу, например [0].\n• Объект — коллекция «ключ — значение». Обозначается фигурными скобками { } и имеет синтаксис {\"key\": value}, где value может иметь атомарный тип, тип массива и объекта. По сути, эта коллекция является ассоциативным массивом, в котором для доступа к значению необходимо использовать строковый ключ.\nСтоит заметить, что документ JSON может содержать в качестве корневого элемента не объект, а массив, например: [ { \"key\": 1 }, { \"key\": 2 }, { \"key\": 3 } ]. Это допустимо. Но в примерах, приводимых в книге, вы будете встречаться с JSONдокументами с корневыми элементами типа «объект».\nПреимущество этого формата текстового файла — возможность описания структур произвольной глубины вложенности (объект внутри объекта, коллекция внутри объекта и пр.), что невозможно в случае табличного представления. Кроме того, существенно упрощается сериализация и десериализация объектов, особенно из JavaScriptприложения. Обработка\n\nJSONфайлов в специализированных СУБД (DocumentDB) описана в книге ниже, а некоторые реляционные базы данных (например, PostgresSQL) широко поддерживают этот формат. Очень важным преимуществом формата JSON является то, что он позволяет строить информационные системы с помощью одной и той же технологии на всех уровнях: начиная с документоориентированной БД, хранящей данные в формате JSON (Azure DocumentDB, MongoDB), бэкенда на основе диалекта JavaScript (например, Node.js) и заканчивая фронтендом на основе того или иного фреймворка JavaScript (например, ReactJS, Angular). Это уникальная возможность, реализованная сейчас только в рамках JavaScript/JSON (например, популярен фреймворк MEAN).\nКнедостаткам JSON можно отнести его «многосимвольность»: для группировки данных используются символы (запятые, скобки, кавычки), которые сами по себе не несут информации. Кроме того, присутствуют имена полей. Перечисленные недостатки проявляются наиболее ярко в случае файлов крупного размера, относящихся к большим данным. Но это неизбежная плата за возможность сериализации/десериализации сложных структур. Избавиться от части избыточных элементов синтаксиса поможет формат YAML, но пока что он используется преимущественно в качестве шаблона конфигурационных файлов (в системах Ansible, CloudFormation и др.), а не для хранения данных. Кроме того, сериализация и десериализация YAML не так широко поддерживается программными библиотеками вводавывода. Выборка значений из документа JSON происходит с первоначальной десериализацией его в объект в программном коде, что наиболее удобно и естественно происходит в языке на основе JavaScript.\nСледующий популярный формат хранения данных в текстовых файлах — XML (eXtensible Markup Language — расширяемый язык разметки). Традиционно он использовался для разметки (markup), то есть структурирования текстовых документов. Термин «язык» (language) говорит о том, что XML содержит строгий набор синтаксических правил, на основании которых можно построить конкретное расширение (extension) этого языка. Рассмотрим, что это значит.\nВ общем случае у XML есть два основных компонента: теги и атрибуты. Тег — синтаксический элемент, ограничивающий конкретную порцию информации: <ИмяТега>Информация в текстовом виде <ИмяТега/>. Любой тег начинается открывающим (<) и закрывающим (>) символами. Информация, представленная в текстовом виде, расположена между тегами, последний из которых состоит из двух символов (/>). Возможны и вложенные структуры тегов и коллекции последних. Атрибуты относятся к конкретному тегу и представляют собой коллекцию «ключ — значение».\nСогласно стандарту XML для тега с конкретным именем существует строго определенный набор атрибутов, причем каждый тег должен содержать\n\nконкретный набор атрибутов или не включать их вовсе. Возможно также построение.\nИтак, язык XML состоит из общих правил построения синтаксиса, а расширение данного языка представляет собой конкретный набор вложенных тегов\nи соответствующих им атрибутов, который обеспечивает упорядоченное представление конкретной структурированной информации. Существует стандартизированный способ преобразования информации из одного XML в другой с помощью XSLT — eXtensible Stylesheet Language Transformation. Это тоже XML, элементами которого является не информация, а правила, по которым она из одного типа XML преобразуется в другой. Кроме того, есть XSD (XML Schema Definition) — синтаксис, описывающий схему, то есть структуру документа. Безусловно, стандарт XML содержит еще ряд других элементов, я описал наиболее употребительные для случаев хранения данных.\nВотличие от JSON XML гораздо более строг и не допускает произвольной вложенности и комбинирования элементов. Например, для одного тега не допускаются разные наборы элементов. Не допускается хранение XML в виде значения атрибута (конечно, так можно сделать, ведь атрибут является текстовым значением, но это очень плохой стиль), в случае коллекции всем ее элементам необходимо иметь совершенно одинаковую схему, то есть набор тегов и атрибутов должен быть одинаков для каждого элемента. В отличие от JSON практически все основные БД поддерживают работу с XML как с самостоятельным типом данных, поскольку он достаточно строг и однозначен. Поддержка в этом случае состоит в предоставлении встроенных средств сериализации таблиц в XML и обратно. Кроме того, XML широко применяется для создания языков описания разметки гипертекстовых документов, при построении пользовательского интерфейса (HTML, XAML, RDLC и пр.).\nНиже представлены достоинства XML как средства хранения информации:\n• строгость синтаксиса существенно упрощает построение систем сериализации/десериализации;\n• этот формат широко поддерживается различными БД как встроенный тип данных;\n• можно выполнить простое прямое преобразование в другие языки, в том числе в языки разметки графических элементов (например, HTML);\n• существуют специальные расширения языка, описывающие различного\nрода преобразования и трансформации (XSLT);\n\n• имеется стандартный способ построения запроса к элементу или выборки элементов (XPath, XQuery).\nК недостатком данного формата можно отнести то, что он гораздо более «многословен», чем JSON, поскольку содержит больше чисто синтаксических символов.\nОблачное хранилище Microsoft Azure Storage\nРассмотрим, как реализовано облачное хранилище, на примере Microsoft Azure Storage. Оно состоит из четырех сервисов: BLOB Storage, Queue Storage, Table Storage и File Storage\nВиды сервисов Azure Storage Account\nНепосредственно хранение информации осуществляется в сервисах BLOB, Table и File Storage. Queue Storage — это облачный сервис обмена сообщениями и синхронизации распределенных приложений. Сервис Table Storage — база данных NoSQL типа «ключ — значение», которая будет подробно описана далее в книге. Пока же сосредоточимся на Azure File и BLOB Storage.\nРассмотрим подробнее, как создавать Azure Storage Account и управлять с вебпортала. Прежде всего необходимо нажать ссылку добавления новых ресурсов Azure, расположенную в левом верхнем углу, — + New. Затем в открывшемся окне выбрать последовательно Storage — Storage account.\n  \nДобавление нового Storage account через веб-портал После нажатия ссылки Storage account откроется форма настройки\nStorage Account.\nФорма настройки Storage Account\nВ ней доступны следующие конфигурации.\n• Имя аккаунта (поле Name) будет частью URL аккаунта\n<Name>.core.windows.net,\n• потому правила наименования ресурсов точно такие же, как и в случае\nименования ресурсов, доступных по URL.\n• Тип модели развертывания ресурсов (deployment model) — выбираем Resource Manager, чтобы иметь возможность добавить аккаунт к общей ресурсной группе PockerRumExample.\n• Тип Storage (Account kind) — Storage (general purpose v1). Помимо этого, доступны типы Storage (general purpose v2) и BLOB.\n• Выбираем уровень производительности (Performance) — Standard. В зависимости от выбранного уровня производительность операций чтениязаписи будет отличаться. Наиболее высоким уровнем будет обладать комбинация Account kind = BLOB, Performance = Premium.\n \nДля premiumуровня в качестве физических устройств хранения выступают SSDдиски.\n• В качестве режима репликации (Replication) выбираем LocallyRedundant storage (LRS). Эта опция означает, что информация, хранящаяся в Storage Account, физически реплицируется три раза, но в пределах одного датацентра. Помимо LRS, доступны различные режимы географической репликации в разных датацентрах в пределах одной зоны (ZRS) или среди нескольких различных зон (GRS и ReadOnlyGRS — репликация по различным географическим зонам с репликой, доступной только для чтения). Все эти режимы различаются по стоимости и уровню надежности и доступности, что позволяет реализовать облачные хранилища, отвечающие различным наборам требований.\nПосле создания Storage Account доступна следующая панель мониторинга и управления\nОбщая панель мониторинга и управления Storage Account\nНа этой панели доступны все четыре сервиса, входящие в состав Storage Account: Blob, File, Table и Queue. Далее в главе рассмотрим Blob Storage и File Storage. Сервис Table Storage представляет собой нереляционную базу данных, а Queue предназначен для синхронизации сервисов «потребитель — производитель».\n "
        }
      },
      {
        "_index" : "lectureindex",
        "_type" : "_doc",
        "_id" : "850d7883-4437-4a1e-a862-6dacf2034cbf",
        "_score" : 1.0,
        "_source" : {
          "_class" : "com.university.entity.elastic.LectureElastic",
          "id" : "850d7883-4437-4a1e-a862-6dacf2034cbf",
          "text" : "Принципы построения, проектирования и эксплуатации ИС. Лекция 12.\n7.1. Общий обзор реляционных хранилищ данных\nРеляционная база данных предназначена для выполнения двух основных функций: OLAP и OLTP. Преимущественно РБД используются для целей OLTP. Это приводит к тому, что, с одной стороны, обычные реляционные базы имеют ограничения по размеру, а с другой — выполнить высокопроизводительные запросы к большим массивам данных может быть затруднительно.\nРассмотрим пример. Предположим, есть база данных SQL, которая служит как хранилище данных веб-приложения, непрерывно обновляемых пользователями. Кроме того, необходимо периодически строить отчеты в системах бизнесаналитики. Для этого нужно выполнить запросы, очень сильно нагружающие SQLсервер, поскольку они будут содержать операции группирования, совершения математических операций, просмотра множества таблиц и соединения в одном запросе результатов просмотра и пр. И тут возможна ситуация, когда запросы от подсистемы бизнес-аналитики могут очень мешать работе веб-приложения и даже блокировать ее из-за зависания базы данных во время выполнения BI запросов. Это происходит потому, что для выполнения таких запросов требуются гораздо большие вычислительные возможности, чем для обычной работы приложения.\nПроблема нехватки ресурсов баз может обостриться ввиду необходимости выполнять запросы к таблицам из разных БД. Она частично устраняется с помощью поднятия ценового уровня базы (для Azure SQL) или типа экземпляра (для AWS RDS) перед запуском всех BI запросов и опускания после их завершения. Но такой подход ограничен тем, что нужно разделить по времени периоды работы сервисов бизнес-аналитики и основного приложения. Кроме того, нерешенной является проблема выполнения запросов среди многих таблиц многих внешних БД. Да и предельно высокий ценовой уровень одиночной базы может оказаться недостаточным. Как быть в этом случае? Вот тут-то на помощь и приходит DWH (Data Warehouse) — «склад данных» — реляционное хранилище данных, оптимизированное для хранения огромных массивов данных и выполнения запросов к ним\n\n Наполнение хранилища Data Warehouse и доступ сторонних сервисов к нему\nВысокая производительность аналитических запросов достигается благодаря массивнопараллельной архитектуре и распараллеливанию запроса для выполнения несколькими серверами одновременно. В данном случае тоже необходимо разместить информацию из различных БД в одном общем сервисе — «складе» (DWH). Преимущество такого подхода в том, что SQL DWH позволяет использовать стандартные SQLзапросы, хранимые процедуры и др., а следовательно, такое хранилище совместимо со всеми стандартными средствами и инструментами BI.\nРеляционное хранилище данных (SQL DWH) представляет собой массивнопараллельное хранилище, состоящее из кластера серверов трех типов: головного (управляющего), узлов вычисления и томов хранения\n Общая архитектура реляционного хранилища данных\n\nКлиент (а точнее, программный клиент) может взаимодействовать с реляционным хранилищем только через головной узел. Последний отвечает за распределение данных по вычислительным узлам, в ряде случаев являющимся одновременно узлами хранения. Кроме того, головной узел компилирует запросы языка SQL в команды кластеру, которые обеспечивают параллельное выполнение, а затем собирает результат вместе и выдает назад клиенту. Реляционное хранилище данных, в отличие от реляционных баз данных, оптимизировано только для целей OLAP. Выполнение транзакций в DWH возможно, но это несвойственно хранилищу, основная задача которого — хранить информацию и предоставлять доступ к ней с помощью интерфейса SQL. При этом производительность запросов на чтение данных существенно выше, чем для обычной БД за счет параллельного выполнения и иного физического представления данных, другого плана выполнения запросов и индексов.\nРассмотрим вопрос параллельного выполнения запросов. Необходимо разделить данные между вычислительными узлами. Это можно сделать следующими способами. Во-первых, в каждом узле разместить идентичные копии данных и разделить запрос таким образом, чтобы каждая его часть в вычислительном узле обрабатывала свой набор строк. Как уже отмечалось, за разделение запроса на подзапросы и соединение их результатов отвечает головной узел. Такая архитектура очень надежна: утеря одного узла никак не повлияет на информацию в хранилище. Недостаток данной архитектуры в том, что из-за ограниченного объема дисков одного узла в нем невозможно хранить очень большие объемы данных. Во-вторых, можно размещать данные в различных узлах без дублирования. При этом вероятно как псевдослучайное распределение строк данных по узлам, так и последовательное, в порядке роста значения ключа. В этом случае возможно хранение и обработка гораздо больших объемов данных, чем в случае их полного копирования в каждом узле.\nИтак, реляционное хранилище данных применяется, когда необходимо получить централизованное хранилище информации, позволяющее выполнять запросы с помощью стандартного синтаксиса SQL, поддерживаемого большинством систем BI. Для этого нужно извлечь данные из внешних источников (extract), преобразовать их к виду, удобному для добавления в хранилище с необходимой обработкой, фильтрацией и пр. (transform) и загрузить их в хранилище (load). Такой подход называется ETL и является традиционным. Он очень удобен в случае, когда внешние источники данных очень разнородны и все вместе или по отдельности не поддерживают встроенный механизм выполнения аналитических запросов. Недостаток ETL состоит в том, что для наполнения реляционного хранилища обязательно нужен сервис копирования и трансформации. Критически важный момент для ETL — метаданные о сторонних источниках: что в них содержится, в каком\n\nформате и др. Эти метаданные в облачных средах могут быть представлены в специальных сервисах — каталогах данных (data catalog).\nРассмотрим логическую структуру информации в реляционном хранилище. Ниже представлены несколько принципов организации реляционных хранилищ данных.\n• Данные в хранилище должны быть объединены в соответствии с категориями предметной области, а не их физическими источниками.\n• Централизованное хранилище должно хранить в своем составе данные, относящиеся ко всей системе в целом, а не только к отдельным аспектам. Только в таком случае можно построить комплексные аналитические запросы. Данные в хранилище содержатся и поступают извне, но не создаются.\n• Говорить о корректности данных в хранилище можно только с привязкой их к конкретному временному промежутку.\nСуществует две стратегии наполнения хранилища данными: стратегия полного обновления (каждый раз происходит полное обновление данных из внешних источников) и инкрементального (обновления только тех данных, которые были изменены в процессе работы OLTP подсистемы). В плане реализации, безусловно, проще стратегия полного обновления, в то время как инкрементальное требует использования сложных ETL процедур замены обновленных элементов, вставки новых и удаления тех, что были удалены в OLTP. Выбрать ту или иную стратегию можно только путем совместного целостного анализа хранилища данных, их источников и характера их изменений.\nЕсть две общие модели построения реляционных хранилищ: нормализованные хранилища и хранилища с измерениями. Построение нормализованного хранилища в общем не отличается от построения нормализованной реляционной базы данных. Информация хранится в связанных таблицах в третьей нормальной форме, и, как следствие, требуется выполнение выборки из многих таблиц, что потенциально ведет к усложнению запросов и падению производительности. Хранилище с измерениями — это денормализованная форма хранения информации. В свою очередь, возможны две архитектуры хранилища с измерениями — в виде схем «звезда» и «снежинка».\nВсхеме «звезда» информация хранится в таблицах двух типов: центральной таблицы фактов и многочисленных таблиц измерений .\n\n Архитектура хранилища данных в виде схемы «звезда»\nв центре звездообразной структуры находится таблица фактов, содержащая информацию, которая будет анализироваться. Она может включать факты (а по сути, записи), связанные с событиями или состоянием объекта, с транзакциями и пр. Таблица содержит первичный ключ, числовые поля, характеризующие данный факт, и внешние ключи, ссылающиеся на таблицу измерений. Числовые поля должны включать аддитивные значения, подлежащие анализу (в том числе суммированию, вычислению среднего значения и др.). Таблицы измерений нужны для хранения атрибутов фактов (как правило, текстовых), которые не могут быть использованы для численных операций со строками таблицы фактов.\nв Например, в таблице фактов с данными о проведенных покерных играх каждая строка содержит сумму выигрыша игрока, внешний ключ на таблицы измерений игроков и игр. В схеме «звезда» данные существенно денормализованы для оптимизации запросов.\nИногда требуется добавить элемент нормализации и расщепить некоторые таблицы изменений на несколько таблиц — это схема «снежинка» .\n Архитектура хранилища данных в виде схемы «снежинка»\n\nВыбор той или иной структуры реляционного хранилища данных и построение запросов (OLAP — кубы, DataMart — витрины данных) является чисто прикладной задачей и архитектура и принцип организации хранилища напрямую зависит от целей его создания и предполагаемого способа использования.\nAzure SQL DWH\nРеляционное хранилище Azure SQL DWH — облачный сервис от Microsoft Azure, построенный на основе сервиса Azure SQL. Этот сервис использует технологию Microsoft PolyBase для построения запросов к данным, расположенным как в хранилище Azure Blob Storage, так и в базах данных Azure SQL. Рассмотрим основные концепции сервиса Azure SQL DWH.\nАрхитектура хранилища Azure SQL DWH соответствует общей архитектуре реляционного храниища, рассмотренной ранее. Как головной узел, так и вычислительные узлы содержат экземпляры системного сервиса DMS (Data Movement Service), отвечающего за передачу данных между узлами. Данные физически хранятся в Azure Storage. Такое физическое разделение их хранения и параллельного выполнения запросов обеспечивает возможность независимого масштабирования объемов хранения и вычислительных мощностей кластера.\nНепосредственно из Azure Storage данные разделяются по вычислительным узлам с помощью одного из трех видов распределения (distributions). Каждый запрос разделяется на 60 меньших фрагментов, каждая из которых выполняется на вычислительном узле. Каждый вычислительный узел работает с 1 до 60 фрагментов в зависимости от его ценового уровня. На наивысшем уровне (максимальная производительность вычислительного узла) используется одно распределение на узел, при минимальных ресурсах — все распределения на один узел.\nСуществует три возможных паттерна данных, влияющих на производительность запросов:\n• распределение с помощью хешфункции (hash);\n• последовательное, или циклическое, распределение (round\nrobin);\n• репликация (replicate).\nИдея использования хешфункции для распределения строк из исходной таблицы по вычислительным узлам состоит в том, что строки равномерно, независимо и случайно разделяются по вычислительным узлам (рис. 7.5). Это позволяет строить оптимальные запросы с помощью соединения таблиц и\n\nагрегации данных. При этом каждая строка таблицы относится к одному распределению.\n Распределение данных таблицы по вычислительным узлам с помощью хешфункции\nЦиклическое распределение строк по вычислительным узлам подразумевает последовательное равномерное наполнение узлов со случайным выбором начального узла. Такое распределение обеспечивает высокую производительность операций выборки данных в случае, когда в соединении таблиц нет нужды, поскольку оно потребует выполнения дополнительных «перетасовок» строк между узлами.\nРепликация применяется при наличии таблиц небольшого размера и состоит том, что такая таблица копируется на все вычислительные узлы. Это позволяет добиться высокой производительности любого типа запроса и одновременно увеличить надежность системы, поскольку отказ одного вычислительного узла или более повлияет лишь на производительность.\n Репликация таблицы по вычислительным узлам\n\nТеперь посмотрим, как работать с Azure SQL DWH из веб-портала. Для этого во вкладке добавления ресурсов в строке поиска следует написать SQL Data Warehouse.\nПосле нажатия кнопки Create (Создать) откроется следующая форма настройки реляционного хранилища Azure SQL DWH.\nЗдесь нужно указать имя базы данных (Database name), выбрать ресурсную группу ( Resource group), сервер (Server) и ценовой уровень производительности (Performance tier).\nДля реляционного хранилища можно настроить ценовой уровень по двум разным критериям: гибкости (Optimized for Elasticity) и вычислительным возможностям (Optimized for Compute). Дадим пояснение величинам, используемым для оценки производительности реляционного хранилища — DWU и cDWU:\n• DWU (Data Warehouse Unit) представляет собой абстрактную величину, описывающую в нормализованном виде доступные вычислительные ресурсы: CPU, память и полоса пропускания дисков данных — IOPS;\n• cDWU (compute Data Warehouse Unit) — с одной стороны, описывает скорость чтения информации из Azure Storage, а с другой — скорость выполнения запросов.\n \nПосле создания Azure SQL DWH панель будет отображать основные возможности Azure SQL DWH, которые близки к таковым у базы данных Azure SQL. На панели представлены отдельный сервис загрузки данных — Load Data (поддерживается загрузка с помощью RedGate и Azure DataFactory), интеграция с сервисом SSAS (ссылка Model and Cache Data), сервис бизнесаналитики (ссылка Open in PowerBI) и, конечно, сервисы мониторинга (Monitoring), масштабирования (Scale), выполнения запросов в онлайн- редакторе (ссылка Open Editor). Кроме того, доступны опции бэкапа, аудита и шифрования.\nВ качестве движка сервиса Azure SQL DWH используется Microsoft SQL DWH и, соответственно, язык запросов TSQL. Чтобы подключить внешний клиент, следует задействовать строку подключения, доступную по ссылке Connection String. Наиболее полная интеграция возможна со средствами бизнес-анализа и аналитики, предоставляемыми корпорацией Microsoft.\n"
        }
      },
      {
        "_index" : "lectureindex",
        "_type" : "_doc",
        "_id" : "e02de984-03b5-4d44-abe9-78358063181b",
        "_score" : 1.0,
        "_source" : {
          "_class" : "com.university.entity.elastic.LectureElastic",
          "id" : "e02de984-03b5-4d44-abe9-78358063181b",
          "text" : "Принципы построения, проектирования и эксплуатации ИС. Лекция 11.\nВнастоящее время Azure предоставляет два сервиса нереляционных хранилищ данных: традиционный Azure Table Storage и Azure CosmosDB. Первый — хранилище типа «ключ — значение». Второй — набор глобально распределенных нереляционных хранилищ, объединенных общей концепцией управления и создания, к которым в настоящее время относятся базы данных DocumentDB и MongoDB (документоориентированные), Gremlin (графовая база данных), Table (таблица типа «ключ — значение») и Cassandra (база данных, относящаяся к типу семейства столбцов).\nНачнем с рассмотрения Azure Table Storage. Этот сервис является встроенным в Azure Storage Account и создается на общей панели, содержащей остальные сервисы (Blob, File и Queue). Общая панель доступа к Azure Table Storage такая же, как и для других сервисов, включенных в Azure Storage. Она очень проста и содержит минимальные опции для конфигурации\nЭто хранилище поддерживает протокол OData для выборки данных на основе протокола HTTP, так что таблица имеет конфигурации для настройки CORS и политики доступа. Сам сервис очень минималистичен, и основное конфигурирование будет происходить не на портале, а с помощью кода\nСамо по себе хранилище Azure Table Storage предназначено для хранения больших объемов (в настоящее время это 500 Тбайт на один Storage Account) структурированных нереляционных данных. Под структурированностью здесь понимается тот факт, что все сущности («строки») представляют собой набор пар «ключ — значение» (причем не обязательно, чтобы он был одинаковым во всех строках). По сути, это огромные таблицы, которые нецелесообразно размещать РБД. В качестве примера можно привести сырые потоковые данные, помещенные таблицу сервисом Stream Analytics Job,\n \nкоторые в итоге должны быть агрегированы сервисом ETL (например, сервисом Azure DataFactory в комбинации с Azure HDInsight Spark) и помещены в реляционное хранилище данных (Azure SQL DataWarehouse) или просто в обычную РБД. При этом желательно сохранить все сырые данные, чтобы в последующем можно было выполнить их интерактивный или интеллектуальный анализ. Azure Table Storage позволяет выполнить такую операцию ввиду того, что способен легко интегрироваться с сервисами копирования, трансформации и потокового анализа данных. Кроме того, поддержка протокола OData для прямого доступа и наличие SDK позволяет получить прямой доступ к табличному хранилищу извне. При этом выполнение высокопроизводительных запросов возможно благодаря встроенному механизму кластерных индексов.\nГлавные компоненты Azure Table Storage\nИтак, Storage Table Account включает в себя набор таблиц, каждая из которых вмещает набор сущностей, то есть строк. Каждая сущность состоит из набора свойств и имеет суммарный размер не более 1 Mбайт. В свою очередь, свойство — это пара «имя — значение». Каждая сущность может иметь до 256 свойств, три из которых обязательны: ключ раздела (partition key), ключ строки (row key) и временная метка (timestamp). Временная метка соответствует времени последней модификации этой сущности. Как уже указывалось, ключ строки должен быть уникальным в пределах раздела, а комбинация «ключ раздела — ключ строки» — уникальной глобально. Для набора, состоящего из сущностей с одинаковым значением ключа раздела, значения могут быть очень быстро выбраны с помощью запроса. Операции вставки/удаления/обновления в данном случае тоже выполняются быстрее. Это возможно потому, что на оба ключа создаются кластерные индексы. Никакие другие индексы создать нельзя.\nТипы данных, которые поддерживаются Table Storage, полностью соответствуют типам данных, доступных в протоколе OData.\nТипы данных стандарта OData\nТип данных CLRтип,\nOData доступный Примечание\n           \n    в коде\n      Edm.Binary Edm.Boolean\nEdm.DateTime\nEdm.Double\nEdm.Guid Edm.Int32 Edm.Int64\nEdm.String\nbyte[ ] Bool\nDateTime\nDouble\nGuid\nint / Int32 long / Int64\nString\nМассив байтов размером до 64 Кбайт\nБулево значение\n64разрядное значение, представляющее собой временную метку UTC\n64разрядное число с плавающей точкой\n128разрядный глобальный идентификатор\n32разрядное целое 64разрядное целое\nСтроковая величина с кодировкой UTF16.\nМаксимальный размер строки — 64 Кбайт\n                                                      Тип по умолчанию — строковый. Для хранения более сложные типы данных должны быть сериализованы в XML или JSON и помещены в строковый формат. Второй вариант — сериализация в двоичный формат и помещение его в битовый массив.\nМодели хранения данных нереляционных хранилищ типа «ключ — значение» не ограничиваются структурами типа «одна большая таблица» или «набор несвязанных таблиц». Можно моделировать отношения и построение таблиц, оптимизированных для решения определенного круга задач (быстрые запросы на выборку, быстрая модификация и пр.).\nРассмотрим теперь базы данных от сервиса Azure CosmosDB. Он является относительно новым и предоставляет единую программную модель для доступа к нереляционным базам разных типов:\n• DocumentDB, она же SQL API, — документоориентированная база данных возможностью выполнения запросов с помощью как SQL, так и JavaScript;\n• MongoDB — облачный сервис хорошо известной базы с таким же названием;\n• Graph API — сервис графовой базы данных, называемой еще Gremlin;\n\n• Table API — дальнейшее развитие базы данных типа «ключ — значение», почти полный аналог Azure Table Storage;\n• Cassandra — сервис, являющийся адаптацией Apache Cassandra.\nУказанные выше базы собраны в единый сервис, предоставляющий всем им ряд общих уникальных черт и свойств. Прежде всего, это глобальная доступность — все перечисленные БД можно реплицировать во все регионы, то есть создать копии баз во всех регионах одновременно! Ну или только в выбранных. При этом в зависимости от географического местоположения клиента его запрос будет направлен к ближайшему дата- центру. Уровень согласованности данных можно настроить вплоть до уровня сильной согласованности (strong consistency). Кроме того, полоса пропускания и размер базы данных могут быть настроены независимо или сконфигурированы на автоматическое расширение. Уровень доступности для этого сервиса (для чтения) гарантируется на уровне 99,99 % применительно к одиночной БД без географической репликации и 99,999 % для репликации в нескольких географических регионах. При этом медианное время задержки в документации указывается равным 5 мс.\nПознакомимся подробнее с сервисом Azure CosmosDB и его возможностями, а затем перейдем к частным типам БД. Прежде всего необходимо создать аккаунт CosmosDB, в рамках которого мы будем создавать базы, а позже и сущности хранения в них. Для создания аккаунта нужно в левом верхнем углу портала нажать на ссылку + New и в появившемся окне поиска выбрать CosmosDB\nПосле нажатия кнопки Create (Создать) появится следующая форма\n \n Прежде всего здесь необходимо указать идентификатор аккаунта (ID), выбрать его тип (API), группу ресурсов (Resource Group), местоположение и включить опцию географического дублирования (Enable georedundancy). Список доступных API в развернутом виде представлен на правой половине рисунка. Вас не должна смущать аббревиатура SQL: имеется в виду база данных SQL API, которая, в свою очередь, соответствует DocumentDB (вероятно, такое странное название было дано в связи с тем, что DocumentDB допускает выполнение запросов к данным, написанным с использованием SQLподобного синтаксиса). Таким образом, при создании нужно выбрать SQL API и нажать кнопку Create (Создать).\nПосле создания аккаунта CosmosDB типа SQL API будет доступна стартовая страница. на Для всех типов поддерживаемых баз данных она выглядит примерно одинаково. Добавить коллекцию можно прямо на стартовой странице, но мы пойдем на вкладку Overview.\n \nПерейдя на вкладку Overview, можно видеть на карте доступные для репликации регионы (прозрачные шестиугольники) и регионы, использованные в настоящий момент (закрашенные шестиугольники). Кроме карты, на этой странице доступна панель мониторинга, которая размещается внизу экрана и не поместилась на снимке.\nЧтобы добавить коллекцию, необходимо нажать ссылку + Add Collection в верхней части экрана, после чего откроется форма, показанная на рис. 6.9. Поскольку\nу нас еще нет баз данных, нужно создать первую базу данных (Database id) —и, далее, в ее рамках создать коллекцию (Collection id) — GameEvents.\nДалее следует выбрать размер хранилища (Storage capacity). Он может быть фиксированным (опция Fixed (10 GB)) и неограниченным (опция Unlimited), то есть автоматически масштабируемым. Кроме того, нужно выбрать производительность (выражена в терминах единиц чтения в секунду) из заданного диапазона. Минимальное значение равно 400. Далее можно добавить в коллекцию документов уникальный ключ (ссылка + Add unique key) и нажать OK.\nТеперь вернемся структуре DocumentDB (а это не что иное, как SQL API). Аккаунты CosmosDB точно так же состоят из одной или нескольких баз данных, которые, в свою очередь, состоят из одной или нескольких коллекций. Эти два элемента сервиса CosmosDB SQL API мы и создали на предыдущем шаге. Каждая коллекция, в свою очередь, состоит из хранимых процедур (stored procedure), определяемых пользователем функций (user defined functions), триггеров (triggers) и собственно документов (documents). Разберем подробнее, что такое документ в терминах DocumentDB, на примере его создания. Для этого на вкладке Data Explorer перейдем к нашим созданным базе данных и коллекции и нажмем ссылку Documents. На появившейся вкладке нажмем на ссылку New Document, в результате изображение на экране будет выглядеть следующим образом.\nИтак, после нажатия на ссылке New Document создается JSONфайл с единственным обязательным полем, равным id. Значение этого поля содержит призыв на английском, который переводится как «замени новым document_id». Это первичный ключ, который должен быть уникальным. В данный документ можно добавить произвольное количество полей, определяемых пользователем. Необходимые изменения, внесенные в документ, показаны в средней части рисунка: первичный ключ равен 1, а пользовательское поле \"custom_key\" — 2. Далее следует нажать ссылку Save. Список созданных документов, для которых первоначально отображаются только ключи, приведен прямо на этой вкладке (под символом id). Если нажать один из этих ключей, то в окне отобразится документ, содержащий наши поля (ключ и пользовательское поле) и еще ряд служебных полей, что видно в нижней части рисунка. Итак, документы — это элементарные порции информации, хранящиеся в DocumentDB в формате\n\nJSON. Как было указано выше, большие данные чаще всего представляют собой большое количество элементарных порций данных, хранящихся в том или ином виде, так вот в DocumentDB элементарной порцией является документ JSON.\nТеперь приведем один пример применения SQLподобного запроса для выборки данных. Сначала нужно добавить несколько документов с различными значениями пользовательского поля.\nСтоит отметить, что, помимо JSONдокументов, документоориентированная база данных позволяет сохранять приложения (attachments) в виде двоичных файлов размером до 2 Гбайт, которые могут быть медиафайлами, архивами и др. (см. свойство \"_attachments\" в нижней части).\nПользовательские функции и хранимые процедуры — написанные на языке JavaScript элементы расширения стандартного синтаксиса запросов, которые\n  \n будут подробнее описаны в части III. Аналоги этих элементов — хранимые процедуры и функции в реляционных базах данных.\nТриггеры представляют собой программные конструкции, написанные на языке JavaScript, вызываемые при выполнении операций на документах. Триггер может выполняться непосредственно перед созданием документа (pretrigger) и после (posttrigger). Очень интересным и важным примером использования триггеров является интеграция с Azure Function — сервисами бессерверного исполнения кода, который может выполняться в ответ на внешний сигнал. Для CosmosDB возможны следующие сценарии запуска (в настоящее время реализованы только для SQL API и Graph API).\nПрименение потока событий изменения (change feed) — перехват Azure Function событий изменений коллекции (добавление/удаление/изменения). При этом поток событий активизирует пользовательский триггер, который, в свою очередь, запускает Azure Function. Данный подход полностью соответствует концепции EventDriven\nИспользование потока событий изменений для вызова Azure Function\nПрименение привязки входа (input binding) — при этом Azure Function читает данные из базы при запуске сторонним триггером (рис. 6.14).\nИспользование Azure Function с привязкой входа\nПрименение привязки выхода (output binding) — в этом случае Azure Function записывает данные в базу в ответ на запуск триггером (рис. 6.15).\nИспользование Azure Function с привязкой выхода\n   \nЭти паттерны полезны в реальных сценариях и позволяют строить сложные приложения, ориентированные как на события (Event Driven), так и на данные (Data Driven).\n"
        }
      },
      {
        "_index" : "lectureindex",
        "_type" : "_doc",
        "_id" : "93e3e886-062d-4ab4-bc1f-f832397db3ea",
        "_score" : 1.0,
        "_source" : {
          "_class" : "com.university.entity.elastic.LectureElastic",
          "id" : "93e3e886-062d-4ab4-bc1f-f832397db3ea",
          "text" : "Принципы построения, проектирования и эксплуатации ИС. Лекция 4.\nКратко рассмотрим возможности конфигурирования Storage Account в целом. Прежде всего, доступен File Explorer — бесплатная программа от Microsoft, позволяющая просматривать содержимое всех сервисов всех аккаунтов хранения.\nНа рисунке можно увидеть результат выборки программы из хранилища Table Storage (таблица events), которая содержит тестовые данные телеметрии, полученные путем приема сообщений через сервисы концентратора EventHub и потоковой аналитики Stream Analytics Job).\n Внешний вид программы File Explorer от Microsoft\nЧтобы обеспечить доступ к аккаунту извне, необходимо знать ключи доступа и URL, которые доступны на вкладке Access Keys\nКлючи доступа и строки подключения к Storage Account\n \nДве пары ключей или строк подключения нужны для обеспечения «бесшовного» обновления ключей. Для этого первоначально используется ключ key1, затем клиенты переключаются на ключ key2, а ключ key1 обновляется. После этого клиенты переключаются на новый ключ key1, а ключ key2 обновляется.\nСтраница конфигурирования аккаунта в целом позволяет менять тип аккаунта (Account kind), уровень производительности (Performance).\n Вкладка конфигурирования типа аккаунта, уровня производительности и репликации\nКподобным манипуляциям следует отнестись внимательно, поскольку каждый уровень имеет различную стоимость, а также переключение между ними может занять время, если в аккаунте много данных.\nСледующий важный конфигурируемый параметр — Shared access signature (SAS)\n \nВкладка конфигурирования типа аккаунта, уровня производительности и репликации\nКонцепция SAS состоит в том, что к объектам, расположенным в Storage Account, можно предоставить прямой доступ для скачивания — с помощью URL, который содержит ряд ограничивающих параметров, а именно: время жизни ссылки и ограничения IPадресов, с которых доступен ресурс. Эти параметры подписываются ключом аккаунта, и данная подпись добавляется в конец URL, по которому данный ресурс может быть доступен.\nТеперь подробнее познакомимся с отдельными сервисами хранения файлов Storage Account.\nСервис Azure BLOB Storage предназначен для хранения различных файлов, потому и называется хранилищем больших двоичных объектов (Binary Large OBjects Storage, BLOB). Двоичные объекты могут храниться в нем как непосредственно, так и будучи размещенными в контейнерах (не путайте с Dockerконтейнерами, речь идет о контейнерах BLOB Storage) или на виртуальных дисках, тоже расположенных в BLOB Storage Account. Чтобы прояснить ситуацию, рассмотрим схему\nСтруктура вложенности объектов в хранилище BLOB\nАккаунт Azure может содержать один или несколько Storage-аккаунтов. Каждый такой аккаунт способен непосредственно хранить файлы, виртуальные жесткие диски и контейнеры BLOB. Последние, в свою очередь, тоже могут включать файлы, виртуальные жесткие диски и другие контейнеры. Таким образом, c помощью контейнеров BLOB реализована иерархическая структура организации файлов.\nНа самом деле в BLOB Storage могут храниться любые файлы: текстовые, двоичные и др., но для разных типов хранимых объектов требуется разный тип BLOB. Всего есть три типа BLOB: Page BLOB, Block BLOB и Append BLOB.\nPage BLOB — бинарный объект со страничной организацией памяти. Этот тип используется только для размещения виртуальных жестких дисков виртуальных машин.\n \nBlock BLOB — BLOB с блочной организацией памяти, служащий для хранения всех видов файлов (кроме VHD), включая контейнеры BLOB. Это основной тип хранения файлов в BLOB Storage обычных файлов.\nAppend Block — BLOB с блочной организацией памяти, представляющий собой текстовый файл, размещенный в Azure Storage и допускающий добавление новой записи в конец файла. В остальных типах BLOB файлы нередактируемые, то есть, чтобы отредактировать файл, его необходимо скачать, открыть, отредактировать и закачать обратно. Понятно, что эти действия сопряжены с большими трудностями при работе с файлами логов. В то же время Append Block как раз оптимизирован для сценариев прямой записи логов.\nВсе объекты, расположенные в BLOB Storage, могут быть доступны через вебпотрал, с помощью SDK, команд расширения командной оболочки, а также по прямой ссылке.\nДоступ к Storage-аккаунту с помощью веб-портала позволяет создавать файлы, контейнеры, просматривать список файлов, добавлять, удалять и загружать их, менять области видимости файлов (они могут быть общедоступными по ссылке, закрытыми для всех, кроме сервисов Azure). Интерфейс веб-портала удобен для работы с небольшим количеством файлов. Добавлять в облачное хранилище через веб-портал можно файлы не слишком большого размера. А вот файлы, загружаемые из облака, могут быть любого размера, допустимого в хранилище. Кроме того, для файлов можно открыть общий доступ, и они станут доступными для скачивания по ссылке. Доступ может быть открыт для файлов как в корневом каталоге, так и в контейнерах внутри хранилища.\nСпособы доступа к файлам в облачном хранилище BLOB\nэДля программного доступа облачный аккаунт содержит REST API, который, свою очередь, через SDK предоставляет гораздо большие возможности: синхронную и асинхронную загрузку и выгрузку, удаление, создание, добавление в конец Append BLOB и пр. Кроме того, через SDK можно создать временную ссылку на файл, то есть ссылку, становящуюся нерабочей через определенный промежуток времени.\nРассмотрим подробнее, как работать с хранилищем BLOB с помощью веб- портала. Чтобы перейти к хранилищу BLOB, необходимо нажать ссылку Blobs на общей панели аккаунта. В результате откроется вкладка\n \n Общая панель сервиса BLOB Storage\nДалее требуется добавить контейнеры. Для этого необходимо нажать ссылку + Container\nФорма создания нового контейнера\nВданной форме указано имя (свойство Name) — pokercomm; уровень доступа (Public access level) — Private (no anonymous access). Этот тип доступа подразумевает доступ не по прямой ссылке, а только с помощью ключей аккаунта с использованием SDK. Другие варианты типа доступа: Blob (anonymous read access for blobs only) — разрешает анонимный доступ только к файлам (BLOB); Container (anonymous read access for containers and blobs) — разрешен анонимный доступ к контейнерам и файлам. Вкладка созданного контейнера выглядит следующим образом\n  \nВкладка созданного контейнера\nЗагрузить файл в контейнер можно с помощью ссылки Upload. Свойства кон тейнера доступны по ссылке Container properties. Они включают в себя имя, адрес, статус, количество и суммарный размер BLOBобъектов, статус.\nВкладка свойств контейнера\nДля контейнера доступна настройка политики доступа через вкладку Access policy. Эта настройка позволяет организовать различный уровень доступа к различным контейнерам и объектам BLOB.\nВкладка настройки политики доступа\nПомимо упомянутых настроек, для BLOB доступен ряд других.\n  \n Различные настраиваемые сервисы Blob Storage\nСамые важные параметры:\n• CORS (сrossorigin resource sharing — совместное использование ресурсов между разными источниками) — свойство, обеспечивающее доступ к ресурсам BLOB из другого домена;\n• Custom domain — конфигурирование DNSзаписей CNAME в целях указания домена пользователя, в дополнение к домену аккаунту Azure Storage;\n• Encryption — шифрование объектов в хранилище;\n• Azure CDN — конфигурирование Azure Content Delivery Network, которая служит для хранения часто используемого контента из хранилища BLOB с анонимным доступом.\nКак уже было сказано, доступ к объектам в BLOB Storage возможен по прямой ссылке URL или с помощью интерфейса REST API (напрямую либо через SDK). Данный способ хранения обеспечивает самый быстрый доступ (минимальное время загрузки/выгрузки), но требует применения специальных программных клиентов, взаимодействующих с этими API. Последнее условие может помешать существующим приложениям большого масштаба мигрировать в облако.\nКроме того, в ряде случаев нужно создать облачное хранилище, которое должно быть доступно из виртуальной машины без всяких «самописных» программных клиентов. Для этого в хранилище BLOB можно разместить\n\nвиртуальный жесткий диск (или набор дисков для RAIDмассива) и примонтировать его к виртуальной машине.\nПреимущество такого решения состоит в том, что данные из виртуальной машины могут быть доступны точно таким же образом, как и c физического диска, подключенного к ней. Недостаток такого способа заключается в его низкой масштабируемости (верхний предел размера ограничен на уровне, определяемом операционной системой виртуальной машины и типом ее устройства ввода-вывода), дороговизне, а также в недоступности файлов извне по прямой ссылке.\nСкорость доступа к файлам тоже определяется конфигурацией топологии соединения дисков в массив RAID и в ряде ситуаций существенно ниже, чем в случае BLOB. Кроме того, один VHD может быть примонтирован строго к одной виртуальной машине. Невозможный или затрудненный доступ к файлам извне, также сложности при конфигурировании совместного доступа к файлам из нескольких виртуальных машин значительно ограничивают возможности такого хранилища в облачных архитектурах для оперирования больших данных. Чтобы преодолеть эти ограничения и одновременно обеспечить работу с файлами стандартными средствами операционных систем и программных библиотек вводавывода, следует использовать облачное файловое хранилище Azure File Storage\nСпособы доступа к облачному файловому хранилищу Azure File Storage\nИтак, сервис Azure File Storage составляет часть Azure Storage Account. Каждый Storage Account может включать в себя одну или несколько шар (share). Чтобы создать новую шару, необходимо c общей панели (см. рис. 4.7) добавить вкладку, нажав + File share. В появившейся форме (рис. 4.21) указывается имя шары (Name) — в нашем примере это pokerfileshare — и\n \nее размер (Quota), в данном случае 10 Гбайт. Размер каждой шары (квота) может изменяться (с помощью вебпортала, SDKуправления облачными ресурсами или Azure CLI) и способна достигать 5 Тбайт.\nФорма добавления новой файловой шары\nКлючевым отличием шары от контейнера является то, что для нее устанавливается квота — верхний предел размера. Эта шара представляет собой корневой каталог, который доступен по протоколу SMB 3.0 и может быть примонтирован\nквиртуальным машинам в том же аккаунте Azure и в том же регионе, что и Azure File Storage.\nНаиболее важными опциями конфигурирования является возможность подключения (Connect) к виртуальной машине и создание мгновенного снимка (View snapshot).\n  Доступные опции конфигурирования файловой шары\n\nЧтобы подключить шару File Storage к виртуальной машине, в оболочке виртуальной машины нужно выполнить команду монтирования сетевого диска. Эта команда может быть получена напрямую на вебпортале после щелчка на ссылке Connect\nВкладка Connect Azure File Storage\nДостоинства файлового хранилища представлены ниже.\n• Возможность прямой миграции файловой системы из локального хранилища в облачное. Будет полностью сохранена иерархия этой системы (вероятные ограничения на символьную длину пути и глубину вложенности каталогов см. в документации).\n• Простота взаимодействия из всех программных продуктов, реализующих стандартные интерфейсы ввода-вывода. Не требуется никаких модификаций кода программ, они могут быть устаревшими и все равно будут работать с Azure File Storage, поскольку это хранилище монтируется к основной файловой системе виртуальной машины на уровне операционной системы.\n \n• Возможен просмотр списка файлов с помощью стандартных средств Windows или Linux.\nНедостатки файлового хранилища:\n• ограниченный размер файловой шары (5 Тбайт) и одного файла (1 Тбайт); более высокая по сравнению с BLOB Storage цена за гигабайт;\n• меньшая по сравнению с BLOB Storage производительность операций чтения-записи.\n"
        }
      },
      {
        "_index" : "lectureindex",
        "_type" : "_doc",
        "_id" : "163c9a99-f935-482f-9f81-cef29d6f872b",
        "_score" : 1.0,
        "_source" : {
          "_class" : "com.university.entity.elastic.LectureElastic",
          "id" : "163c9a99-f935-482f-9f81-cef29d6f872b",
          "text" : "1. 2.\nЛЕКЦИЯ No6\n«Основные конфигурационные файлы Linux» по дисциплине\n«Основы администрирования программно-аппаратных комплексов под управлением ОС Linux»\nКонфигурационные файлы Linux\nПринципы редактирования конфигурационных файлов Linux\n1.Конфигурационные файлы Linux\nПоскольку операционная система — это всего лишь набор программ и ядро, то все конфигурационные файлы были созданы определенными программами и читаются ими же для настройки поведения. Большинство файлов, которые мы привыкли считать стандартными, относятся к системе инициализации или к другим системным утилитам. Большинство файлов размещено в /etc. Название этой папки расшифровывается как «et cetera», что с латинского означает «и другие» или «и так далее».\nЕсли просмотреть содержимое etc – нетрудно потеряться. Рассмотрим основные конфигурационные файлы.\n/etc/adjtime\nЭтот конфигурационный файл отвечает за настройку формата системного времени и читается службой systemd-timedated. Время может быть представлено в двух вариантах: LOCAL — время текущего часового пояса и UTC — время по Гринвичу.\n/etc/bash.bashrc\nЭтот файл принадлежит командной оболочке bash. Это не совсем конфигурационный файл — а скрипт, его содержимое выполняется при запуске каждого экземпляра bash для настройки оболочки. Точно так же выполняется содержимое файла ~/.bashrc для каждого пользователя.\n/etc/crontab\nCrontab — файл настройки планировщика cron. Здесь записываются все задания, которые должен выполнить планировщик, а также время и периодичность. Этот файл не принято редактировать напрямую. Для этого используется утилита crontab -e.\n/etc/environment\nЗдесь содержатся переменные окружения, которые будут загружены для каждого сеанса терминала, независимо от того запущен он на локальной машине или по ssh. Файл читается скриптами Bash во время инициализации оболочки.\n/etc/fstab\nНаверное, все уже знают файл /etc/fstab. Здесь выполняется настройка монтирования файловых систем во время загрузки. В современных системах он читается systemd и все записи на ходу транслируются в юнит-файлы, с помощью которых уже выполняется монтирование.\n/etc/group\n\nВ этом файле хранятся все группы пользователей, которые есть в системе. С помощью него вы можете посмотреть список групп, их идентификаторы или добавить новые. Но добавлять группы с помощью редактирования файла не принято, для этого есть утилита usermod.\n/etc/hostname\nВ этом файле содержится имя хоста, файл будет прочитан во время загрузки системы и указанное имя компьютера установится в системе. Вы будете его видеть в приглашении ввода терминала или в информации о системе.\n/etc/hosts\nФайл /etc/hosts позволяет задавать псевдонимы для различных сетевых узлов. Таким образом, компьютер не обращается к DNS для получения IP домена, а берет его из hosts. Это позволяет, например, заблокировать доступ к нежелательным сайтам просто перенаправив их на localhost или же получить доступ к сайту по ip, которому еще не присвоен домен. /etc/hosts.allow И /etc/hosts.deny\nС помощью этих двоих файлов можно настраивать права доступа ко всем локальным службам. Например, вы можете разрешить доступ к службе apache только с локального компьютера. Это очень сильно повысит безопасность системы, если ваш компьютер подключен к публичной сети.\n/etc/issue И /etc/issue.net\nБаннер, который будет выводиться при входе в командную оболочку локально или по SSH. Обычно там выводится версия ядра и дистрибутива Linux, но вы можете заменить эту информацию по своему усмотрению.\n/etc/ls.so.conf\nВ этом файле содержатся пути к папкам, в которых компоновщик linux ld.so будет искать динамические библиотеки во время запуска программ. Папки /lib64, /lib, /usr/lib64 и /usr/lib будут проверены автоматически.\n/etc/localtime\nЭто символическая ссылка, которая указывает на файл часового пояса в папке /usr/share/zoneinfo/. Редактировать файл не нужно, а для изменения настроек нужно создать символическую ссылку на другую временную зону.\n/etc/login.defs\nФайл /etc/login.defs отвечает за настройку поведения утилиты управления пользователями и параметры входа в систему. Вы можете настроить какой минимальный и максимальный id нужно выдавать, что делать с папкой пользователя при удалении и многое другое, количество попыток входа и таймаут, а также многое другое.\n/etc/mime.types\nВ этом файле содержатся общесистемные правила преобразования расширений файлов в понятные системе MIME типы данных. Затем уже система выбирает, чем открыть тот или иной тип данных.\n/etc/modprobe.d/\nПапка /etc/modprobe содержит конфигурационные файлы со списками модулей ядра, которые не нужно загружать при старте системы, псевдонимами для существующих модулей, а также позволяет задавать настройки для модулей.\n/etc/modules-load.d\n\nПапка /etc/modules-load.d/ содержит файлы со списками модулей, которые должны быть загружены при запуске системы. Имя файла не важно, но он должен иметь расширение .conf.\n/etc/nsswitch.conf\nЭтот файл задает настройки порядка разрешения имен в системе для всех программ, написанных на Си или С++. Например, нужно сначала просматривать локальную сеть и систему, или сразу же отправлять запрос к DNS.\n/etc/ntp.conf\nФайл ntp.conf отвечает за настройку службы синхронизации времени — ntpd. В файле указаны адреса ntp серверов, с которых служба будет получать время, а также общие настройки.\n/etc/os-release\nОтображает очень подробную информацию об установленном дистрибутиве:\n/etc/passwd\nФайл содержит список всех зарегистрированных в системе пользователей, а также дополнительные настройки для них, например, оболочку, дату смены пароля и дату отключения аккаунта, кроме самого пароля. Напрямую файл лучше не редактировать, а использовать утилиту для управления пользователями adduser или deluser.\n/etc/profile\nФайл /etc/profile, точно так же как и /etc/environment загружается и выполняется при запуске любой командной оболочки в системе. Но в отличие от environment, это скрипт, а значит, он может задавать не только переменные, но и выполнять различные команды для инициализации оболочки.\n/etc/resolv.conf\nВ этом файле содержатся IP адреса DNS серверов, которые будет использовать компьютер. В большинстве дистрибутивов вы можете редактировать файл вручную или же использовать специальные утилиты.\n/etc/sddm.conf\nЭто конфигурационный файл Linux для настройки менеджера входа sddm, для других менеджеров входа будут свои файлы настройки. Здесь можно изменить максимальный и минимальный ID пользователя, который может войти в систему, например, чтобы разрешить авторизацию root, изменить тему, добавить вход без пароля и многое другое. /etc/shadow\nРаньше пароли пользователя содержались в файле /etc/passwd, но поскольку к нему мог получить доступ любой пользователь, это было небезопасно, несмотря на то, что пароли зашифрованы. Поэтому все пароли были вынесены в /etc/shadow. Вы можете изменить пароль пользователя.\n/etc/sudoers\n/etc/sudoers — это файл настройки прав доступа к утилите sudo. Эта утилита позволяет выполнять команды от имени других пользователей, в том числе от имени суперпользователя. Но использовать ее могут только те пользователи, которые прописаны в этом файле.\n/etc/sysctl.conf\nЭтот файл отвечает за настройку параметров ядра во время выполнения. Тут вы можете задать все параметры из подсистемы /sys/ и они будут сохранены после перезагрузки. /etc/vconsole.conf\n\nУ этого файла только одна цель — задать кодировку, раскладку клавиатуры и шрифт по умолчанию для всех виртуальных консолей, запускаемых на машине.\n/boot/grub/grub.cfg\nЭтот конфигурационный файл Linux находится не в /etc из-за своего особого предназначения. Здесь содержатся все настройки загрузчика, пункты меню и другие параметры, поэтому он должен быть доступен еще до того как была подключена корневая файловая система.\n2.Принципы редактирования конфигурационных файлов Linux\nПрактически все настройки практически всех приложений, включая системные компоненты, хранятся в виде обычных текстовых файлов различного формата, называемых конфигурационными файлами или просто «конфигами». Это очень удобно, поскольку позволяет просто читать и менять их не только из конкретного приложения. Нормальные программы обычно содержат встроенный редактор параметров, основные настройки системы так же можно легко изменить с помощью графических утилит, доступных из меню «Система». Однако некоторые операции требуют редактирования системных файлов конфигурации, к которым нет доступа из графического окружения. Большинство конфигурационных файлов, которые приходится редактировать вручную, к тому же доступны для изменения только пользователю с привилегиями root. Если вам неоходимо отредактировать подобный файл, то вы можете поступить несколькими способами:\nСамый простой путь: вызвать диалог запуска программ (по умолчанию - Alt+F2) и запустить обычный текстовый редактор с правами суперпользователя командой:\ngksu gedit /путь/до/файла\nПользователи Kubuntu должны подставить вместо gedit текстовый редактор KDE kate. У вас попросят ввести ваш пароль и, если вы являетесь администратором компьютера, откроется для редактирования нужный файл.\nТо же самое можно сделать из терминала, запустив редактор командой\nsudo gedit /путь/до/файла\nВ этом случае вместо графического окна с запросом пароля у вас появится запрос непосредственно в терминале.\nПри введении пароля в терминале на экране ничего не отображается, ни звѐздочек, ни чѐрточек, ни каких-либо других символов, это нормально и так и должно быть, просто вводите пароль и нажимайте Enter\nНу и наконец можно отредактировать текстовый файл непосредственно из терминала, не открывая графических приложений вообще. Существует масса текстовых редакторов для терминала, самыми популярными в среде линуксойдов являются vi и emacs, однако ни первым, ни вторым новичку пользовать в принципе нереально, поэтому лучше всего использовать простой в освоении редактор nano, доступный по умолчанию в любой версии Ubuntu. Для открытия текстового файла с правами суперпользователя в nano просто наберите в терминале\nsudo nano /путь/до/файла\nЕсли для доступа к конфигурационному файлу требуются права администратора, то, скорее всего, в нѐм содержатся какие-то важные системные настройки. Будьте предельно внимательны при редактировании таких файлов, ошибка может привести к\n\nнеработоспособности всей системы. Если всѐ же случилось так, что вы записали в конфиг что-то не то - всегда можно загрузиться с LiveCD и исправить любой файл.\nДля редактирование некоторых конфигурационных файлов права администратора не требуются и поэтому являются излишними, в этом случае достаточно просто убрать sudo или gksu из начала команды и всѐ делать так же, как уже описано.\nКритические системные файлы\nСуществует несколько критических конфигурационных файлов, от содержимого которых зависит в системе очень многое, классическим примером является файл /etc/sudoers. Для редактирования конкретно этого файла существует специально адаптированная версия редактора vi, которую можно вызвать командой\nsudo visudo\nБудьте предельно внимательны при изменении подобных файлов, неправильная информация в /etc/sudoers может крайне просто привести к невозможности выполнить что-либо в системе.\n"
        }
      },
      {
        "_index" : "lectureindex",
        "_type" : "_doc",
        "_id" : "d3a552ae-f589-4376-b369-e3e0c5763892",
        "_score" : 1.0,
        "_source" : {
          "_class" : "com.university.entity.elastic.LectureElastic",
          "id" : "d3a552ae-f589-4376-b369-e3e0c5763892",
          "text" : "ЛЕКЦИЯ No7\n«Развертывание и тонкая настройка ОС Linux» по дисциплине\n«Основы администрирования программно-аппаратных комплексов под управлением ОС Linux»\n1.Настройка файервола iptables.\n2. Полезные программы и утилиты Linux\n1.Настройка файервола iptables.\nIptables — утилита командной строки, является стандартным интерфейсом управления работой межсетевого экрана (брандмауэра) Netfilter для ядер Linux, начиная с версии 2.4. С еѐ помощью администраторы создают и изменяют правила, управляющие фильтрацией и перенаправлением пакетов. Для работы с семейством протоколов IPv6 существует отдельная версия утилиты — Ip6tables. Для использования утилиты Iptables требуются привилегии суперпользователя (root).\nОсновные понятия\nКлючевыми понятиями iptables являются:\nПравило — состоит из критерия, действия и счетчика. Если пакет соответствует критерию, к нему применяется действие, и он учитывается счетчиком. Критерия может и не быть — тогда неявно предполагается критерий «все пакеты». Указывать действие тоже не обязательно — в отсутствие действия правило будет работать только как счетчик. Правила для каждой цепочки срабатывают в порядке их следования, поэтому порядок важен.\nКритерий — логическое выражение, анализирующее свойства пакета и/или соединения и определяющее, подпадает ли данный конкретный пакет под действие текущего правила. Критерии соединяются логическим «И».\nДействие — описание действия, которое нужно проделать с пакетом и/или соединением в том случае, если они подпадают под действие этого правила. О действиях более подробно будет рассказано ниже.\nСчетчик — компонент правила, обеспечивающий учет количества пакетов, которые попали под критерий данного правила. Также счетчик учитывает суммарный объем таких пакетов в байтах.\nЦепочка — упорядоченная последовательность правил. Цепочки можно разделить на пользовательские и базовые.\nБазовая цепочка — цепочка, создаваемая по умолчанию при инициализации таблицы. Каждый пакет, в зависимости от того, предназначен ли он самому хосту, сгенерирован им или является транзитным, должен пройти положенный ему набор базовых цепочек различных таблиц. Кроме того, базовая цепочка отличается от пользовательской наличием «действия по умолчанию» (default policy). Это действие применяется к тем пакетам, которые не были обработаны другими правилами этой цепочки и вызванных из нее\n    \nцепочек. Имена базовых цепочек всегда записываются в верхнем регистре (PREROUTING, INPUT, FORWARD, OUTPUT, POSTROUTING).\nПользовательская цепочка — цепочка, созданная пользователем. Может использоваться только в пределах своей таблицы. Рекомендуется не использовать для таких цепочек имена в верхнем регистре, чтобы избежать путаницы с базовыми цепочками и встроенными действиями.\nТаблица — совокупность базовых и пользовательских цепочек, объединенных общим функциональным назначением. Имена таблиц (как и модулей критериев) записываются в нижнем регистре, так как в принципе не могут конфликтовать с именами пользовательских цепочек. При вызове команды iptables таблица указывается в формате -t имя_таблицы. При отсутствии явного указания, используется таблица filter.\nБазовая конфигурация\nНиже приведѐн пример базовой статической конфигурации iptables. При сохранении и загрузке подобной конфигурации необходимо принимать во внимание возможность внесения в неѐ изменений со стороны других сервисов, например Fail2ban. Кроме того, при использовании IPv6-адресации конфигурацию для IPv6 следует выполнять независимо от IPv4.\nIPv4\nПросмотр текущей конфигурации:\nsudo iptables-save\nСоздаѐм скрипт с дампом правил iptables:\nsudo nano /etc/network/if-up.d/iptables-rules\nКопируем следующий код:\n#!/sbin/ip6tables-restore\n# Таблица filter и еѐ цепочки\n*filter\n:INPUT ACCEPT [0:0]\n:FORWARD ACCEPT [0:0]\n:OUTPUT ACCEPT [0:0]\n# Разрешаем связанные и установленые соединения\n-A INPUT -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT\n# Разрешаем служебный icmp-трафик\n-A INPUT -p ipv6-icmp -j ACCEPT\n# Разрешаем доверенный трафик на интерфейс loopback\n-A INPUT -i lo -j ACCEPT\n# Сюда можно вставлять дополнительные правила для цепочки INPUT\n# Запрещаем всѐ остальное для INPUT\n-A INPUT -j REJECT --reject-with icmp6-adm-prohibited\n# Порядок и смысл правил для цепочек FORWARD и OUTPUT аналогичен INPUT\n-A FORWARD -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT\n-A FORWARD -p ipv6-icmp -j ACCEPT\n-A FORWARD -j REJECT --reject-with icmp6-adm-prohibited\n# Фильтровать цепочку OUTPUT настоятельно не рекомендуется\n#-A OUTPUT -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT\n#-A OUTPUT -p ipv6-icmp -j ACCEPT\n#-A OUTPUT -o lo -j ACCEPT\n \n#-A OUTPUT -j REJECT --reject-with icmp6-adm-prohibited COMMIT\nДополняем нужными правилами с учѐтом ip6tables-save. Сохраняем и закрываем: Ctrl+O, Enter, Ctrl+X\nДелаем скрипт исполняемым и загружаем правила iptables: sudo chmod +x /etc/network/if-up.d/ip6tables-rules\nsudo /etc/network/if-up.d/ip6tables-rules\nНебольшое замечание по терминологии. Фаервол, встроенный в ядро Linux, называется Netfilter, а iptables — утилита для управления этим фаерволом. Многие ошибочно полагают, что фаервол называется iptables. Это не так. Категорически не стоит что-нибудь наподобие «я фильтрую пакеты с помощью iptables».\n2. Полезные программы и утилиты Linux Программы для работы с сетью и интернетом\nТип программы Windows программа Linux программа\nMozilla Firefox, Opera, Chromium, Google Chrome, Lynx, Konqueror,\n      Web-браузер\nКлиент обмена мгновенными сообщениями\nIRC-клиент\nГолосовое/видео общение\nE-mail клиенты\nMidori, SRWare Iron\nInternetExplorer w3m, links, luakit\nPidgin, Gajim, qutIM, ICQ, Skype\nQIP, Miranda, Mail.ru агент, Windows Live Messenger\nEmpathy, Kopete, MyAgent-IM\n   Pidgin, Xchat\nMIRC Konversation Skype, SFLphone, Ekiga, Linphone, Jitsi, QuteCom\nTwinkle\nMozilla Thunderbird, SeaMonkey, Opera Mail, Sylpheed, Claws Mail\n   Microsoft Outlook, Outlook Express, The Bat!\nEvolution, KMail, Postler,Fetchmail\nGwget, Kget, D4X, FatRat, uGet,\n Менеджеры загрузок cURL, JDownloader, aria2, wget Download Master, Free Download\n   \n   Тип программы\ntorrent- клиенты\nDC- клиенты\ned2k-клиенты\nFTP-клиенты\nRSS-агрегаторы\nWindows программа Linux программа\nManager, FlashGet, Orbit SteadyFlow Downloader\nVuze, Deluge, qBittorrent, Transmission\n     BitTorrent, μTorrent\nEiskaltDC++\nDC++, StrongDC++, FlylinkDC++\naMule\neMule\nFilezilla\nTotal Commander Thunderbird, RSSOwl Outlook\nFlush, KTorrent, FatRat, rTorrent, CTorrent, MLDonkey\nLinuxDC++, Valknut, FreeDC++,Nicotine+, Museek+\nxMule, MLDonkey\nTucan Manager, gFTP\n     Клиенты облачных хранилищ данных\nLiferea, Akregator, Claws Mail Dropbox, Wuala, SpiderOak, Ubuntu One\n Windows Live Mesh, SugarSync Расширение возможностей\nownCloud\nLinux программа\nX Neural Switcher\n       Тип программы\nАвтоматический переключатель раскладки\nЗаметки\nWindows программа Punto Switcher\n  Tomboy, Zim, NeverNote, Makagiga\nEvernote Gnote, Xpad, MyTetra\n   \n   Тип программы\nУкрашения рабочего стола\nДок-бар\nОфисные приложения Тип программы\nЭлектронные словари\nТекстовые редакторы\nПакет офисных приложений\nCистема оптического распознавания текстов (OCR)\nОрганайзеры, записные книжки\nПерсональные информационные менеджеры (PIM)\nПодготовка публикаций\nWindows программа Linux программа\nWindows Aero, Боковая панель Compiz Fusion , Plasma, Screenlets, Windows, Aston Google Gadgets, Conky\n     RocketDock, ObjectDock\nCairo-Dock, Avant Window Navigator, Docky , wBar\n      Windows программа Linux программа GoldenDict, StarDict\nABBYY Lingvo\nGedit   , Medit, Vim, Geany, SciTE, Emacs\n  Notepad, Notepad++, AkelPad\nKate, Nano, JOE, Leafpad, Mousepad, Sublime Text 2\n  LibreOffice   , OpenOffice.org, GNOME Office, SoftMaker Office\n  Microsoft Office, Corel WordPerfect Office\nKoffice, Calligra\nCuneiform, Tesseract\nFineReader, Readiris YAGF\nSunbird, Tomboy, Lightning (Thunderbird) Rainlendar\n   Microsoft Outlook\nLaTeX, LyX, Kile, Scribus Adobe InDesign\nKdepim, Evolution, Osmo\n   \n   Тип программы Просмотр PDF/DJVU\nПрограммы для чтения FB2, TXT, RTF, TCR, HTML, EPUB\nWindows программа Linux программа Evince, Adobe Reader, Foxit Reader\nSTDU Viewer,WinDjView , Okular, Xpdf, Zathura, Sumatra PDF ePDFView, Gv\nFBReader, Cool Reader 3, Calibre KeePassX, LastPass\n    Менеджеры паролей\nПрограммы для работы с файлами\n  KeePass, Password Safe, Password Saver\nWindows программа Linux программа Nero Burning ROM\nCDBurnerXP, Deep\nBurner, Infra Recorder, Brasero   , K3b, GnomeBaker, Graveman, cdw ImgBurn\nPeaZip\n7-Zip, WinRAR, WinZIP tar   , Squeeze, p7zip, File Roller   , Ark, Xarchiver\nDouble Commander\nExplorer, Far manager, Nautilus   , Thunar, Dolphin, Konqueror, Total Commander, Unreal PCManFM, SpaceFM (развитие PCManFM), Commander emelFM2, Gentoo, Midnight Commander,\nSeahorse\n     Тип программы\nПрограммы для записи оптических дисков\n  Работа с архивами\nФайловые менеджеры\nМонтирование образов\nAlcohol 120%, Daemon Tools\nKrusader, Gnome-commander\nAcetoneISO, Furius ISO Mount, Mount, CDemu\n         Системные утилиты\n\n   Тип программы\nСоздание/изменение/удаление файловых систем\nВосстановление\nдля файловых систем\nБинарные редакторы\nРасширенные настройки системы\nАнтивирусы\nWindows программа Linux программа\n  PartitionMagic, Acronis Disk Director Suite\ngparted, KDE Partition Manager, Palimpsest Disk Utility, fdisk, cfdisk, sfdisk\n  R-Studio TestDisk, Ext3Grep, ExtUndelete, MagicResque\n  Ultimate Windows Tweaker, XP Tweaker\nBless, Okteta, Hexedit\nubuntu tweak, Ailurus, KernelCheck\n  ClamAV, DrWeb, Nod32, Avast, Avira AntiVir, Kaspersky Workstation, BitDefender\n "
        }
      },
      {
        "_index" : "lectureindex",
        "_type" : "_doc",
        "_id" : "c0f62441-b598-4dd6-b0ab-dbd3855dbbc1",
        "_score" : 1.0,
        "_source" : {
          "_class" : "com.university.entity.elastic.LectureElastic",
          "id" : "c0f62441-b598-4dd6-b0ab-dbd3855dbbc1",
          "text" : "Принципы построения, проектирования и эксплуатации ИС. Лекция 10.\nКлассический принцип организации CI/CD для AZURE DATA FACTORY\nВ Azure Data Factory непрерывная интеграция и доставка (CI/CD) означает перемещение конвейеров Data Factory из одной среды (разработка, тестирование, производство) в другую. Для использования CI/CD можно использовать интеграцию Data Factory UX с шаблонами менеджера ресурсов Azure Data Factory (ARM TEMPLATE).\nДля целей развертывания в AZURE используется специальные шаблоны AZURE Resource Manager для каждой среды/\n  В интерфейсе фабрики данных можно сгенерировать такой шаблон с помощью экспорта ARM TEMPLATE, в результате чего будет создан шаблон для открытой в интерфейсе фабрики данных и файл конфигурации, включающий все строки подключения и другие параметры. Затем создаются файлы конфигурации для каждой из сред (разработка, тестирование и т.д.). Базовый файл шаблона остается без изменений и одинаков для всех сред.\nСтандартная схема автоматизации непрерывной интеграции с помощью релизов Azure Pipelines\nНа рисунке приведена стандартная схема Azure Pipelines для автоматизации развертывания ADF в нескольких средах.\n \n Настройка выпусков через AZURE DEVOPS Pipelines\nДля настройки простого механизма развертывания в Azure DevOps необходимо пройти следующую процедуру:\n 1. В AZURE DEVOPS откройте проект, настроенный на фабрику данных.\n 2. На левой стороне страницы выберите Pipelines, а затем выберите Releases.\n3. Выберите New pipeline или, если у вас есть существующие конвейеры,\nвыберите New, а затем New release pipeline.\n4. Выберите пустой шаблон службы.\n \n 5. Внесите название среды развертывания в Stage name.\n6. Добавьте новый артефакт, а затем выберите репозиторий с фабрикой\nданных. Выберите adf_publish для ветки по умолчанию. Для версии по умолчанию - выберите Latest from default branch.\n   7. Добавьте задачу развертывания Azure Resource Manager. а. В представлении этапа выберите View stage tasks.\n  \n b. Создайте новое задание Azure Resource Group Deployment. c. В задаче развертывания выберите подписку, группу ресурсов и\nместоположение для фабрики данных.\nd. В списке действий выберите Create or update resource group.\ne. Выберите ранее экспортированный файл с ARM шаблоном - находится в папке ветки adf_publish.\nf. В Template parameters необходимо выбрать файл ARMTemplateParametersForFactory.json, который может быть стандартным файлом настроек или содержать изменения.\ng. В Override template parameters необходимо внести изменения для фабрики назначения. Для учетных данных, получаемых из Azure Key Vault, имя ключа вводится между двойными кавычками.\nh. Необходимо выбрать Incremental в Deployment mode.\nПри выборе Complete в Deployment mode существующие ресурсы могут быть удалены полностью!\n \n 8. Сохраните pipeline\n9. Запуск развертывания производится выбором Create release.\n   В результате релиза ADF будет развернут на целевую среду.\nПолучение паролей из Azure Key Vault\n1. Добавить секреты в файл параметров.\nЕсли у вас есть пароли для передачи в ARM Template Azure, то для их хранения и развертывания рекомендуется использовать Azure Key.\nСуществует два способа обработки паролей:\n  Создается копия файла параметров, загруженного в ветку\nпубликации. Установливаются значения параметров, которые нужно получить от Key Vault, используя следующий формат:\nJSONКопировать\n  {\n    \"parameters\": {\n        \"azureSqlReportingDbPassword\": {\n            \"reference\": {\n                \"keyVault\": {\n                    \"id\":\n\"/subscriptions/<subId>/resourceGroups/<resourcegroupId> /providers/Microsoft.KeyVault/vaults/<vault-name> \"\n},\n\n } }\n}\n    \"secretName\": \" < secret - name > \"\n}\nПри использовании этого метода пароли будут автоматически извлекаться из хранилища.\nФайл параметров должен находиться в ветви публикации.\n2. Добавить задачу Azure Key Vault перед задачей развертывания ARM:\n 1. В задаче «Azure Key Vault» необходимо выбрать подписку, в которой создано хранилище ключей и внести параметры доступа\n   Использование пользовательских параметров с шаблоном ARM\nЕсли подключен GIT, можно переопределить свойства по умолчанию в шаблоне ARM для установки свойств, которые параметризируются в шаблоне, и свойств, которые\n вностятся жестко(hardcode). В некоторых случая может потребоваться переопределить шаблон параметризации по умолчанию:\n • используется автоматизированный CI/CD и нужно изменить некоторые свойства во время развертывания диспетчера ресурсов, но свойства не параметризируются по умолчанию.\n• В шаблоне больше, чем максимально допустимое количество параметров (256 шт.).\n \nВ этом случае, чтобы переопределить шаблон параметризации по умолчанию, создается файл с названием arm-template-parameters-definition.json в папке, указанной в качестве корневой папки для git. Data Factory считывает этот файл из той ветви, которая выбрана на портале Azure Data Factory. Если файл не найден, используется шаблон по умолчанию.\n Синтаксис пользовательского файла параметров\nФайл параметров состоит из разделов для каждого типа сущности: триггер, конвейер, связанная служба, набор данных, время выполнения интеграции и так далее.\n • путь свойства указывается под соответствующим типом сущности.\n• Установка имени свойства в * используется для указания того, что необходимо\nпараметризировать все свойства под ним (только до первого уровня, а не\nрекурсивно).\n• Установка значения свойства как строки указывает на то, что свойство\nпараметризируется, при этом формат записи следующий: <action>:<name>:<stype> .\n o <action> может быть одним из этих символов:\n ▪ = -означает сохранение текущего значения в качестве значения по умолчанию для параметра.\n▪ - - означает отсутствие значения по умолчанию для параметра.\n▪ | - это специальный знак для строк или ключей соединения из Azure Key\nVault.\n o <name> — это название параметра. Если он пуст, он берет название\nсвойства. Если значение начинается с символа «-», то имя\nсокращается. Например, AzureStorage1_properties_typeProperties_conne ctionString будет сокращен до AzureStorage1_connectionString .\no <stype>-этотиппараметра.Если<stype>пуст,поумолчаниюиспользуется тип string. Поддерживаемые значения типов: string, bool, number, object и securestring .\n • Указание массива в файле определения указывает на то, что соответствующее свойство в шаблоне является массивом. Data Factory итерирует все объекты в массиве, используя определение, указанное в объекте времени выполнения интеграции массива. Второй объект, строка, становится именем свойства, которое используется в качестве имени параметра для каждой итерации.\n• Определение не может быть специфичным для экземпляра ресурсов. Любое\n определение применяется ко всем ресурсам такого типа.\n• По умолчанию параметризируются все объекты безопасности, такие как пароли\nKey Vault, а также строки соединения, ключи и токены.\n  Связанные шаблоны Resource Manager\nПри использовании CI/CD для фабрик данных, существует вероятность превысить пределы шаблона ресурсов ARM из-за роста размера фабрики. Например, одним из ограничений является максимальное количество ресурсов в шаблоне. Для работы с\n \nбольшими фабриками для шаблона фабрика теперь генерирует связанные ARM шаблоны вместо одного большого. С помощью этой функции вся загрузка на фабрику разбита на несколько файлов, чтобы избежать ограничений.\nВ Git, связанные шаблоны генерируются и сохраняются в adf_publish в отдельной папке linkedTemplates:\n   Связанные шаблоны обычно состоят из основного шаблона и набора связанных с ним подчиненных шаблонов. Родительский шаблона называется ArmTemplate_master.json, а подчиненные шаблоны именуются в виде ArmTemplate_0.json, ArmTemplate_1.json и так далее.\nЧтобы использовать связанные шаблоны вместо полного нужно обновить задачу CI/CD, и выбрать ArmTemplate_master.json вместо ArmTemplateForFactory.json. Менеджер ресурсов также требует, хранения связанных шаблонов в Storage account, чтобы Azure мог получить к ним доступ во время развертывания.\nИспользование ветки Hotfix\nИногда в продуктивной среде ADF требуется быстро исправить ошибку, но не возможно вывести интеграционную ветку. Для решения этой проблемы рекомендется создать и использовать для исправления ветку HotFix следующим образом:\n 1. В Azure DevOps найдите релиз, который был развернут в продуктивную\n среду. Выберите последний выпущенный коммит.\n2. Из сообщения о коммите получите идентификатор в интеграционной ветке.\n3. Создайте новую ветку hotfix из этого коммита.\n4. Перейдите на UX-фабрику данных Azure и переключитесь на ветку hotfix.\n5. Используя Фабрику данных Azure UX, исправьте ошибку. Проверьте свои\nизменения.\n6. После проверки исправления выгрузите ARM шаблон hotfix.\n7. Вручную проверьте эту сборку в adf_publish ветке.\n \n8. Если настроен релизный pipeline на изменения adf_publish, то новый релиз запустится автоматически, если нет, то необходимо запустить релиз вручную.\n9. Необходимо протащить изменения из hotfix в ветку разработки, чтобы исключить потерю hotfix изменений .\n "
        }
      },
      {
        "_index" : "lectureindex",
        "_type" : "_doc",
        "_id" : "cab3d937-029e-4577-bc43-d7add55a523f",
        "_score" : 1.0,
        "_source" : {
          "_class" : "com.university.entity.elastic.LectureElastic",
          "id" : "cab3d937-029e-4577-bc43-d7add55a523f",
          "text" : "Принципы построения, проектирования и эксплуатации ИС. Лекция 9.\nПроцесс разработки начинается с создания пустой системы, системы из шаблона или выделения новой ветки для существующей системы.\nРазработка в Azure Data Factory производится только в ветках CI, FIX, TEMPLATE. Обычно запрещается вносить какие-либо изменения напрямую в интеграционные ветки development и master. После окончания разработки производится слияние ветки разработки с интеграционной веткой.\nРазработка в Azure Data Lake Store ведётся только в папках #DEVELOPMENT. После окончания разработки производится перенос элементов в структуру папок верхнего уровня.\nРазработка в Azure Databricks ведётся только в папке BRANCH. Запрещается вносить изменения в каталогах DEVELOPMENT, RELEASE. После окончания разработки производится автоматический перенос блокнотов в каталог RELEASE с затиранием всех данных в каталоге и последующем выводе всех блокнотов из ветки.\nРазработка в Azure Database ведётся только в схемах с префиксом Dev_:\nПосле релиза в UAT среду и тестирования запускается процедура переноса разработки в продуктивную среду.\n \nСохранение структур данных Azure Database в ветку разработки\nПри создание новой ветки разработки на все таблицы и хранимые процедуры установлен триггер который автоматически сохраняет все изменения вносимые в хранимые процедуры, схемы таблиц с префиксом Dev_ в ветку разработки.\nИзменения внесенные в хранимые процедуры сохраняться в ветку разработки в каталог database по пути /database/{SystemName} с именем {StoredProcedureName}.sql.\nИзменения внесенные в схемы таблиц сохраняться в ветку разработки в каталог database по пути /database/{SystemName} с именем {TableName}_SCHEMA.sql.\n \nСохранение настроек в ветку разработки\nВсе настройки с типом Durable хранимые в таблице сохраняются в ветку разработки в виде CSV-файла.\n При внесении изменений в таблицу параметров срабатывает триггер записывающий информацию об имениях в таблицу ParametersChange на записи в данную таблицу происходит событие на срабатывание pipeline Azure DevOps который генерирует CSV с Durable параметрами и коммитит полученный CSV-файл в ветку разработки.\nСоздание пустой системы\nДля создания новой системы необходимо проделать вручную или автоматизировать следующие действия:\n• Новая ветка в системе контроля версий Git с именем указанным в переменной BranchName\n• Пустые pipeline со стандартными имена в Azure Data Factory помещенные в каталог с именем системы\n• Каталог в Azure Databricks с именем системы для разработки блокнотов по следующему пути /BRANCH/{BRANCHNAME}/{SYSTEMNAME}\n• Таблицы в Azure Database\no Таблицы генерации скриптов и параметров в схеме Dev_Setting o Таблицы мониторинга в схеме Dev_Monitoring\no Таблицы QC в схеме Dev_QC\n• Структура каталогов в Azure Data Lake Store\n\no RAW/FILES/#DEVELOPMENT/{BRANCHNAME}/{SYSTEMNAME} o PROCESS/#DEVELOPMENT/{BRANCHNAME}/{SYSTEMNAME} o OUTPUT/#DEVELOPMENT/{BRANCHNAME}/{SYSTEMNAME}\nШаблоны разработки\nШаблонами разработки являются наборы Pipeline & notebook располагающихся в папке TEMPLATES.\nОбычно разрабатываются шаблоны доставки данных в зависимости от типа источника, например, MSSQL, ORACLE, POSTGRESQL, SFTP и т.д.\nТакже нередко существует дополнительное выделение в качестве шаблонов алгоритмы и механизмы извлечения данных, например, различные алгоритмы извлечения данных в виде Delta по версии записи, алгоритмы извлечения по фиксации изменения в дополнительных таблицах, изменения данных связанные с датой модификации файлов и другие.\nТакие шаблоны могут быть использованы для формирования pipeline и скриптов загрузки новой системы на основе шаблонизированного и параметризированного шаблона.\nПри этом важно реализовать механизмы обновления уже созданных элементов при изменении шаблонов.\nТакие механизмы могут быть реализованы через стандартный механизм ARM TEMPLATE в Azure Data Factory, или с помощью механизмов автоматизации AZURE DevOps с потоковой трансформацией структур всех JSON представлений pipeline в ветке и возвратом изменений.\nБолее сложный вариант используется в том случае, если в рамках шаблона используются не только элементы ADF, но и другие, связанные структуры, например, скрипты Azure Data Bricks.\n\nСоздание Pull Request\nДля создания Pull Request необходимо в Azure Data Factory перейти в ветку, в которой велась разработка и нажать кнопку Publish. После нажатия будет выведено диалоговое с предложениеv создать Pell Reuqest, со следующим содержимым «Publish is only allowed from collaboration ('development') branch. Merge the changes to 'development'.» Необходимо перейти по ссылке «Merge the changes to 'development'»\n Проверяем ветку из который будут выводиться изменения и интеграционную ветку. После проверок нажимаем Create.\n На следующем этапе проверяем возникшие конфликты, решаем их и по завершению нажимаем Complete.\n\nВ появившемся диалоговом окне «Complete pull request» убираем чекбокс «Delete {SOURCE_BRANCHNAME} after merging» и нажимаем Complete merge.\nВетка разработки была влита в интеграционную ветку.\nПодключение блокнотов Azure Databricks к системе контроля версий\nДля сохранений изменений и версионирования блокнотов Azure Databricks разработка должна вестись только с использованием системы контроля версий Git. При создании новой ветки все блокноты автоматически линкуются к репозиторию Git, но при создании нового блокнота понадобиться добавить его в Git вручную (см. п. Подключение нового блокнота).\nПодключение нового блокнота\nПосле создание нового блокнота его необходимо подключить Git репозиторию, для этого необходимо выбрать панель Revision History, нажать на ссылку Git: not linked, после чего откроется диалоговое окно Git Preferences. В открывшемся окне необходимо изменить статус блокнота на Link, указать ссылку до репозитория (https://marsanalytics@dev.azure.com/marsanalytics/RUSSIA%20DATA%20FOUNDATION/_git/russ ia-data-foundation) выбрать необходимую ветку и изменить путь блокнота согласно следующему шаблону:\n1. В начале пути добавить каталог data-bricks\n2. Удалить каталог BRANCH\n3. Удалить имя ветки\n \nПример:\nБыло: notebooks/BRANCH/ci-hydrateatlas/APOLLODEMAND/APOLLODEMAND_QC.py\nНеобходимо: data-bricks/notebooks/APOLLODEMAND/APOLLODEMAND_QC.py\n  \nРегламент написания кода в Azure Databricks\nРегламент написания кода приводится в документе “Регламент написания Python кода в Azure Databricks”\nВывод разработки в UAT\nПосле завершение разработки в своей ветке необходимо вывести все изменения в интеграционную ветку development. Для этого в своей ветке разработки CI необходимо создать Pull Request (см. п. Создание Pull Request) на вывод всех имений в интеграционную ветку.\nОтветственный за UAT разработчик должен принять Pull Request или отказать в приеме с обоснованием и указанием недостатков, которые требуется устранить до подачи повторного запроса. Для проверки корректности запроса на слияние необходимо выполнить обязательную процедуру проверки всех внесённых изменений в Azure Data Factory с помощью кнопки Validate All для каждого изменения. Для изменений Azure Databricks и изменений других элементов выполняется CodeReview.\nВ случае принятия запроса ответственный должен произвести публикацию всех изменений для UAT (нажать кнопку Publish для публикации изменений в Data Factory и запуска Azure DevOps pipeline с выводом изменений остальных элементов).\n При публикации изменений в Data Factory будет сгенерирован ARM шаблон который будет помещен в ветку adf_publish. После генерации, автоматически по срабатыванию триггера, будет запущен Azure DevOps pipeline который выведет из интеграционной ветки следующие изменения:\n• Блокноты Azure Databricks\n• Приложение логики Logic App\n• Синхронизирует параметры\n\n• Синхронизирует схемы таблиц Azure Database\n• Синхронизирует хранимые процедуры Azure Database для генерации скриптов\nВывод разработки в Production\nПо завершению тестирования в UAT среде необходимо провести слияние интеграционной ветки development разработки с интеграционной веткой продуктива master.\nОтветственный за продуктив разработчик должен принять Pull Request или отказать в приеме с обоснованием и указанием недостатков, которые требуется устранить до подачи повторного запроса. Для проверки корректности запроса на слияние необходимо выполнить обязательную процедуру проверки всех внесённых изменений в Azure Data Factory с помощью кнопки Validate All для каждого изменения. Для изменений Azure Databricks и изменений других элементов выполняется CodeReview.\nВ случае принятия запроса ответственный должен произвести публикацию всех изменений для продуктива (нажать кнопку Publish для публикации изменений в Data Factory и запуска Azure DevOps pipeline с выводом изменений остальных элементов).\n При публикации изменений в Data Factory будет сгенерирован ARM шаблон который будет помещен в ветку adf_publish. После генерации, автоматически по срабатыванию триггера,\nбудет запущен изменения:\n• • • • •\nAzure DevOps pipeline который выведет из интеграционной ветки следующие\nБлокноты Azure Databricks\nПриложение логики Logic App\nСинхронизирует параметры\nСинхронизирует схемы таблиц Azure Database\nСинхронизирует хранимые процедуры Azure Database для генерации скриптов\n"
        }
      }
    ]
  }
}